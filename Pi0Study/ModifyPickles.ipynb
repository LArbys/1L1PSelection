{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is code to add new variables to the pickle files for use in the pi0 study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2\n",
      "Welcome to JupyROOT 6.14/08\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "%matplotlib inline\n",
    "import platform\n",
    "print(platform.python_version())\n",
    "from ROOT import TFile,vector\n",
    "import ROOT\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from math import sqrt,acos,cos,sin,pi,exp,log,isnan,atan2\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import asarray\n",
    "from root_pandas import read_root\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import asarray as ar,exp\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import LogFormatterMathtext\n",
    "import math\n",
    "import json\n",
    "\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from math import sqrt,acos,cos,sin,pi,exp,log,isnan,atan2\n",
    "from numpy import asarray\n",
    "from root_pandas import read_root\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import quad\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "from textwrap import wrap\n",
    "import copy\n",
    "\n",
    "import seaborn as sns\n",
    "import SupportingFunctions as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded everything\n"
     ]
    }
   ],
   "source": [
    "# load in pickle files to modify\n",
    "pickledir = '../data/pickles/'\n",
    "date = 'Nov_20'\n",
    "\n",
    "# MC sample\n",
    "tag = date+'_run1_numu'\n",
    "pickle_numu_goodruns_pmtprecut = (pickledir+'numu_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Feb_4_run1_numu_v1'\n",
    "pickle_numu_goodruns_pmtprecut_1Mil = (pickledir+'numu_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_run1_nue_v1'\n",
    "pickle_nue_goodruns_pmtprecut = (pickledir+'nue_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = date+'_run1_ext'\n",
    "pickle_ext_goodruns_pmtprecut = (pickledir+'ext_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = date+'_run3_ext'\n",
    "pickle_ext_r3_goodruns_pmtprecut = (pickledir+'ext_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_run3_numu_v1'\n",
    "pickle_numu_r3_goodruns_pmtprecut = (pickledir+'numu_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_run3_nue_v1'\n",
    "pickle_nue_r3_goodruns_pmtprecut = (pickledir+'nue_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = date+'_run2_numu'\n",
    "pickle_numu_r2_goodruns_pmtprecut = (pickledir+'numu_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Mar_19_run2_numu_1Mil'\n",
    "pickle_numu_r2_goodruns_pmtprecut_1Mil = (pickledir+'numu_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_run2_nue'\n",
    "pickle_nue_r2_goodruns_pmtprecut = (pickledir+'nue_goodruns_precuts_%s.pickle'%tag)\n",
    "\n",
    "tag = 'Jan_15_run1_CCPi0'\n",
    "pickle_ccpi0_r1_goodruns_pmtprecut = (pickledir+'%s.pickle'%tag)\n",
    "tag = 'Jan_15_run3_CCPi0'\n",
    "pickle_ccpi0_r3_goodruns_pmtprecut = (pickledir+'%s.pickle'%tag)\n",
    "tag = 'May_20_run1_NCPi0'\n",
    "pickle_ncpi0_r1_goodruns_pmtprecut = (pickledir+'%s.pickle'%tag)\n",
    "tag = 'May_20_run3_NCPi0'\n",
    "pickle_ncpi0_r3_goodruns_pmtprecut = (pickledir+'%s.pickle'%tag)\n",
    "# tag = 'Jan_15_run3b_NCPi0'\n",
    "# pickle_ncpi0_r3b_goodruns_pmtprecut = (pickledir+'%s.pickle'%tag)\n",
    "\n",
    "# pi0 data\n",
    "# tag = date+'_pi0box_run1'\n",
    "# pickle_data_r1_pi0filter_pmtprecut = (pickledir+'data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = date+'_pi0box_run2D'\n",
    "# pickle_data_r2d_pi0filter_pmtprecut = (pickledir+'data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = date+'_pi0box_run2E'\n",
    "# pickle_data_r2e_pi0filter_pmtprecut = (pickledir+'data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = date+'_pi0box_run3F'\n",
    "# pickle_data_r3f_pi0filter_pmtprecut = (pickledir+'data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = date+'_pi0box_run3G'\n",
    "# pickle_data_r3g_pi0filter_pmtprecut = (pickledir+'data_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = date+'_open_run1'\n",
    "pickle_data_goodruns_pmtprecut = (pickledir+'data_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'far_C1'\n",
    "pickle_data_far_c1_pi0filter_pmtprecut = (pickledir+'data_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'far_2D'\n",
    "pickle_data_far_d2_pi0filter_pmtprecut = (pickledir+'data_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'far_2E'\n",
    "pickle_data_far_e2_pi0filter_pmtprecut = (pickledir+'data_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'far_3F'\n",
    "pickle_data_far_f3_pi0filter_pmtprecut = (pickledir+'data_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'far_G1'\n",
    "pickle_data_far_g3_pi0filter_pmtprecut = (pickledir+'data_goodruns_precuts_%s.pickle'%tag)\n",
    "\n",
    "# fake data pickles\n",
    "# tag = 'Apr_14_fake1_run3'\n",
    "# pickle_fakedata1_goodruns_run3_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Apr_14_fake1_run1'\n",
    "# pickle_fakedata1_goodruns_run1_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Apr_14_fake2_run3'\n",
    "# pickle_fakedata2_goodruns_run3_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Apr_14_fake2_run1'\n",
    "# pickle_fakedata2_goodruns_run1_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Apr_14_fake3_run3'\n",
    "# pickle_fakedata3_goodruns_run3_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Apr_14_fake3_run1'\n",
    "# pickle_fakedata3_goodruns_run1_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Apr_14_fake4_run3'\n",
    "# pickle_fakedata4_goodruns_run3_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Apr_14_fake4_run1'\n",
    "# pickle_fakedata4_goodruns_run1_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Apr_14_fake5_run1'\n",
    "# pickle_fakedata5_goodruns_run1_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Apr_14_fake7_run3'\n",
    "# pickle_fakedata7_goodruns_run3_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Apr_14_fake7_run1'\n",
    "# pickle_fakedata7_goodruns_run1_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "\n",
    "# detectorvariations\n",
    "# run3_numu_CV = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_overlay_CV.root\"\n",
    "# run3_numu_LYAtt = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_LYAttenuation.root\"\n",
    "# run3_numu_LYRayleigh = \"/media/disk1/kmason/mcc9_v40_dl_run3b_bnb_nu_overlay_DetVar_LYRayleigh.root\"\n",
    "# run3_numu_LYDown = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_LYdown.root\"\n",
    "# run3_numu_Recomb = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_recomb2.root\"\n",
    "# run3_numu_SCE =\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_SCE.root\"\n",
    "# run3_numu_WiremodScaleddEdx = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodscaleddedx.root\"\n",
    "# run3_numu_WiremodThetaXZ = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodThetaXZ.root\"\n",
    "# run3_numu_WiremodThetaYZ = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodThetaYZ.root\"\n",
    "# run3_numu_WiremodYZ = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodYZ.root\"\n",
    "# run3_numu_WiremodX = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_overlay_wiremodX.root\"\n",
    "# # numu_CV_df = read_root(run3_numu_CV, 'dlana/FinalVertexVariables')\n",
    "# numu_wmodX_df = read_root(run3_numu_WiremodX, 'dlana/FinalVertexVariables')\n",
    "# numu_wmodYZ_df = read_root(run3_numu_WiremodYZ, 'dlana/FinalVertexVariables')\n",
    "# numu_thetaXZ_df = read_root(run3_numu_WiremodThetaXZ, 'dlana/FinalVertexVariables')\n",
    "# numu_thetaYZ_df = read_root(run3_numu_WiremodThetaYZ, 'dlana/FinalVertexVariables')\n",
    "# numu_dedx_df = read_root(run3_numu_WiremodScaleddEdx, 'dlana/FinalVertexVariables') \n",
    "# numu_SCE_df = read_root(run3_numu_SCE, 'dlana/FinalVertexVariables')\n",
    "# numu_LYdown_df = read_root(run3_numu_LYDown, 'dlana/FinalVertexVariables')\n",
    "# numu_LYR_df = read_root(run3_numu_LYRayleigh, 'dlana/FinalVertexVariables')\n",
    "# numu_LYAtt_df = read_root(run3_numu_LYAtt,'dlana/FinalVertexVariables')\n",
    "# numu_recomb_df = read_root(run3_numu_Recomb,'dlana/FinalVertexVariables')\n",
    "\n",
    "# make data frames\n",
    "# print(pickle_numu_goodruns_pmtprecut)\n",
    "df_numu_goodruns_pmtprecut = pd.read_pickle(pickle_numu_goodruns_pmtprecut)\n",
    "df_numu_goodruns_pmtprecut_1Mil = pd.read_pickle(pickle_numu_goodruns_pmtprecut_1Mil)\n",
    "df_nue_goodruns_pmtprecut = pd.read_pickle(pickle_nue_goodruns_pmtprecut)\n",
    "df_ext_goodruns_pmtprecut = pd.read_pickle(pickle_ext_goodruns_pmtprecut)\n",
    "df_data_goodruns_pmtprecut = pd.read_pickle(pickle_data_goodruns_pmtprecut)\n",
    "df_numu_r3_goodruns_pmtprecut = pd.read_pickle(pickle_numu_r3_goodruns_pmtprecut)\n",
    "df_nue_r3_goodruns_pmtprecut = pd.read_pickle(pickle_nue_r3_goodruns_pmtprecut)\n",
    "df_ext_r3_goodruns_pmtprecut = pd.read_pickle(pickle_ext_r3_goodruns_pmtprecut)\n",
    "# df_data_r3_open_pmtprecut = pd.read_pickle(pickle_data_r3_open_pmtprecut)\n",
    "df_numu_r2_goodruns_pmtprecut = pd.read_pickle(pickle_numu_r2_goodruns_pmtprecut)\n",
    "df_numu_r2_goodruns_pmtprecut_1Mil = pd.read_pickle(pickle_numu_r2_goodruns_pmtprecut_1Mil)\n",
    "df_nue_r2_goodruns_pmtprecut = pd.read_pickle(pickle_nue_r2_goodruns_pmtprecut)\n",
    "df_ccpi0_r1_goodruns_pmtprecut = pd.read_pickle(pickle_ccpi0_r1_goodruns_pmtprecut)\n",
    "df_ccpi0_r3_goodruns_pmtprecut = pd.read_pickle(pickle_ccpi0_r3_goodruns_pmtprecut)\n",
    "df_ncpi0_r1_goodruns_pmtprecut = pd.read_pickle(pickle_ncpi0_r1_goodruns_pmtprecut)\n",
    "df_ncpi0_r3_goodruns_pmtprecut = pd.read_pickle(pickle_ncpi0_r3_goodruns_pmtprecut)\n",
    "# df_ncpi0_r3b_goodruns_pmtprecut = pd.read_pickle(pickle_ncpi0_r3b_goodruns_pmtprecut)\n",
    "\n",
    "# df_data_r1_pi0filter_pmtprecut = pd.read_pickle(pickle_data_r1_pi0filter_pmtprecut)\n",
    "# df_data_r2d_pi0filter_pmtprecut = pd.read_pickle(pickle_data_r2d_pi0filter_pmtprecut)\n",
    "# df_data_r2e_pi0filter_pmtprecut = pd.read_pickle(pickle_data_r2e_pi0filter_pmtprecut)\n",
    "# df_data_r3f_pi0filter_pmtprecut = pd.read_pickle(pickle_data_r3f_pi0filter_pmtprecut)\n",
    "# df_data_r3g_pi0filter_pmtprecut = pd.read_pickle(pickle_data_r3g_pi0filter_pmtprecut)\n",
    "df_data_far_c1_pi0filter_pmtprecut = pd.read_pickle(pickle_data_far_c1_pi0filter_pmtprecut)\n",
    "df_data_far_d2_pi0filter_pmtprecut = pd.read_pickle(pickle_data_far_d2_pi0filter_pmtprecut)\n",
    "df_data_far_e2_pi0filter_pmtprecut = pd.read_pickle(pickle_data_far_e2_pi0filter_pmtprecut)\n",
    "df_data_far_f3_pi0filter_pmtprecut = pd.read_pickle(pickle_data_far_f3_pi0filter_pmtprecut)\n",
    "df_data_far_g3_pi0filter_pmtprecut = pd.read_pickle(pickle_data_far_g3_pi0filter_pmtprecut)\n",
    "\n",
    "\n",
    "# df_fakedata1_goodruns_run3_pmtprecut = pd.read_pickle(pickle_fakedata1_goodruns_run3_pmtprecut)\n",
    "# df_fakedata1_goodruns_run1_pmtprecut = pd.read_pickle(pickle_fakedata1_goodruns_run1_pmtprecut)\n",
    "# df_fakedata2_goodruns_run3_pmtprecut = pd.read_pickle(pickle_fakedata2_goodruns_run3_pmtprecut)\n",
    "# df_fakedata2_goodruns_run1_pmtprecut = pd.read_pickle(pickle_fakedata2_goodruns_run1_pmtprecut)\n",
    "# df_fakedata3_goodruns_run3_pmtprecut = pd.read_pickle(pickle_fakedata3_goodruns_run3_pmtprecut)\n",
    "# df_fakedata3_goodruns_run1_pmtprecut = pd.read_pickle(pickle_fakedata3_goodruns_run1_pmtprecut)\n",
    "# df_fakedata4_goodruns_run3_pmtprecut = pd.read_pickle(pickle_fakedata4_goodruns_run3_pmtprecut)\n",
    "# df_fakedata4_goodruns_run1_pmtprecut = pd.read_pickle(pickle_fakedata4_goodruns_run1_pmtprecut)\n",
    "# df_fakedata5_goodruns_run1_pmtprecut = pd.read_pickle(pickle_fakedata5_goodruns_run1_pmtprecut)\n",
    "# df_fakedata7_goodruns_run3_pmtprecut = pd.read_pickle(pickle_fakedata7_goodruns_run3_pmtprecut)\n",
    "# df_fakedata7_goodruns_run1_pmtprecut = pd.read_pickle(pickle_fakedata7_goodruns_run1_pmtprecut)\n",
    "\n",
    "# put dataframes in a list for loops\n",
    "df_list=[]\n",
    "df_list_mc=[]\n",
    "df_list_data=[]\n",
    "\n",
    "# df_list.append(df_data_r1_pi0filter_pmtprecut)\n",
    "# df_list.append(df_data_r2d_pi0filter_pmtprecut)\n",
    "# df_list.append(df_data_r2e_pi0filter_pmtprecut)\n",
    "# df_list.append(df_data_r3f_pi0filter_pmtprecut)\n",
    "# df_list.append(df_data_r3g_pi0filter_pmtprecut)\n",
    "df_list.append(df_data_goodruns_pmtprecut)\n",
    "df_list.append(df_data_far_c1_pi0filter_pmtprecut)\n",
    "df_list.append(df_data_far_d2_pi0filter_pmtprecut)\n",
    "df_list.append(df_data_far_e2_pi0filter_pmtprecut)\n",
    "df_list.append(df_data_far_f3_pi0filter_pmtprecut)\n",
    "df_list.append(df_data_far_g3_pi0filter_pmtprecut)\n",
    "\n",
    "# df_list.append(df_fakedata1_goodruns_run3_pmtprecut)\n",
    "# df_list.append(df_fakedata1_goodruns_run1_pmtprecut)\n",
    "# df_list.append(df_fakedata2_goodruns_run3_pmtprecut)\n",
    "# df_list.append(df_fakedata2_goodruns_run1_pmtprecut)\n",
    "# df_list.append(df_fakedata3_goodruns_run3_pmtprecut)\n",
    "# df_list.append(df_fakedata3_goodruns_run1_pmtprecut)\n",
    "# df_list.append(df_fakedata4_goodruns_run3_pmtprecut)\n",
    "# df_list.append(df_fakedata4_goodruns_run1_pmtprecut)\n",
    "# df_list.append(df_fakedata5_goodruns_run1_pmtprecut)\n",
    "# df_list.append(df_fakedata7_goodruns_run3_pmtprecut)\n",
    "# df_list.append(df_fakedata7_goodruns_run1_pmtprecut)\n",
    "\n",
    "\n",
    "df_list.append(df_numu_goodruns_pmtprecut)\n",
    "df_list.append(df_numu_goodruns_pmtprecut_1Mil)\n",
    "df_list.append(df_nue_goodruns_pmtprecut)\n",
    "df_list.append(df_ext_goodruns_pmtprecut)\n",
    "df_list.append(df_numu_r2_goodruns_pmtprecut)\n",
    "df_list.append(df_numu_r2_goodruns_pmtprecut_1Mil)\n",
    "df_list.append(df_nue_r2_goodruns_pmtprecut)\n",
    "df_list.append(df_numu_r3_goodruns_pmtprecut)\n",
    "df_list.append(df_nue_r3_goodruns_pmtprecut)\n",
    "df_list.append(df_ext_r3_goodruns_pmtprecut)\n",
    "df_list.append(df_ccpi0_r1_goodruns_pmtprecut)\n",
    "df_list.append(df_ccpi0_r3_goodruns_pmtprecut)\n",
    "df_list.append(df_ncpi0_r1_goodruns_pmtprecut)\n",
    "df_list.append(df_ncpi0_r3_goodruns_pmtprecut)\n",
    "# df_list.append(df_ncpi0_r3b_goodruns_pmtprecut)\n",
    "\n",
    "# df_list_data.append(df_data_r1_pi0filter_pmtprecut)\n",
    "# df_list_data.append(df_data_r2d_pi0filter_pmtprecut)\n",
    "# df_list_data.append(df_data_r2e_pi0filter_pmtprecut)\n",
    "# df_list_data.append(df_data_r3f_pi0filter_pmtprecut)\n",
    "# df_list_data.append(df_data_r3g_pi0filter_pmtprecut)\n",
    "df_list_data.append(df_data_far_c1_pi0filter_pmtprecut)\n",
    "df_list_data.append(df_data_far_d2_pi0filter_pmtprecut)\n",
    "df_list_data.append(df_data_far_e2_pi0filter_pmtprecut)\n",
    "df_list_data.append(df_data_far_f3_pi0filter_pmtprecut)\n",
    "df_list_data.append(df_data_far_g3_pi0filter_pmtprecut)\n",
    "\n",
    "# df_list_data.append(df_fakedata1_goodruns_run3_pmtprecut)\n",
    "# df_list_data.append(df_fakedata1_goodruns_run1_pmtprecut)\n",
    "# df_list_data.append(df_fakedata2_goodruns_run3_pmtprecut)\n",
    "# df_list_data.append(df_fakedata2_goodruns_run1_pmtprecut)\n",
    "# df_list_data.append(df_fakedata3_goodruns_run3_pmtprecut)\n",
    "# df_list_data.append(df_fakedata3_goodruns_run1_pmtprecut)\n",
    "# df_list_data.append(df_fakedata4_goodruns_run3_pmtprecut)\n",
    "# df_list_data.append(df_fakedata4_goodruns_run1_pmtprecut)\n",
    "# df_list_data.append(df_fakedata5_goodruns_run1_pmtprecut)\n",
    "# df_list_data.append(df_fakedata7_goodruns_run3_pmtprecut)\n",
    "# df_list_data.append(df_fakedata7_goodruns_run1_pmtprecut)\n",
    "\n",
    "\n",
    "df_list_mc.append(df_numu_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_numu_goodruns_pmtprecut_1Mil)\n",
    "df_list_mc.append(df_nue_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_numu_r2_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_numu_r2_goodruns_pmtprecut_1Mil)\n",
    "df_list_mc.append(df_nue_r2_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_numu_r3_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_nue_r3_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_ccpi0_r1_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_ccpi0_r3_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_ncpi0_r1_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_ncpi0_r3_goodruns_pmtprecut)\n",
    "# df_list_mc.append(df_ncpi0_r3b_goodruns_pmtprecut)\n",
    "\n",
    "print(\"loaded everything\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new has pi0 flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in text files\n",
    "# newflag_run1=open('2021Mar19_newhaspi0_run1.txt','r')\n",
    "# newflag_run2=open('2021Mar19_newhaspi0_run2.txt','r')\n",
    "newflag_run3=open('2021Mar19_newhaspi0_run3.txt','r')\n",
    "newflag_run1_1mil=open('2021Mar19_newhaspi0_run1_1mil.txt','r')\n",
    "newflag_run2_1mil=open('2021Mar19_newhaspi0_run2_1mil.txt','r')\n",
    "\n",
    "# get lists\n",
    "run_mu_1_1mil = []\n",
    "subrun_mu_1_1mil = []\n",
    "event_mu_1_1mil = []\n",
    "\n",
    "run_mu_2_1mil = []\n",
    "subrun_mu_2_1mil = []\n",
    "event_mu_2_1mil = []\n",
    "enu_true_mu_2_1mil =[]\n",
    "\n",
    "run_mu_3 = []\n",
    "subrun_mu_3 = []\n",
    "event_mu_3= []\n",
    "\n",
    "# for line in newflag_run1:\n",
    "#     vals = line.split(\",\")\n",
    "#     run_mu_1.append(int(vals[0]))\n",
    "#     subrun_mu_1.append(int(vals[1]))\n",
    "#     event_mu_1.append(int(vals[2]))\n",
    "    \n",
    "for line in newflag_run1_1mil:\n",
    "    vals = line.split(\",\")\n",
    "    run_mu_1_1mil.append(int(vals[0]))\n",
    "    subrun_mu_1_1mil.append(int(vals[1]))\n",
    "    event_mu_1_1mil.append(int(vals[2]))\n",
    "    \n",
    "# for line in newflag_run2:\n",
    "#     vals = line.split(\",\")\n",
    "#     run_mu_2.append(int(vals[0]))\n",
    "#     subrun_mu_2.append(int(vals[1]))\n",
    "#     event_mu_2.append(int(vals[2]))\n",
    "#     enu_true_mu_2.append(float(vals[3]))\n",
    "\n",
    "for line in newflag_run2_1mil:\n",
    "    vals = line.split(\",\")\n",
    "    run_mu_2_1mil.append(int(vals[0]))\n",
    "    subrun_mu_2_1mil.append(int(vals[1]))\n",
    "    event_mu_2_1mil.append(int(vals[2]))\n",
    "    enu_true_mu_2_1mil.append(float(vals[3]))\n",
    "\n",
    "for line in newflag_run3:\n",
    "    vals = line.split(\",\")\n",
    "    run_mu_3.append(int(vals[0]))\n",
    "    subrun_mu_3.append(int(vals[1]))\n",
    "    event_mu_3.append(int(vals[2]))\n",
    "    \n",
    "# loop through the dataframes and textfiles to find list\n",
    "def newhaspi0flag(df,run_list,subrun_list,event_list,energy_list=[],run2=False):\n",
    "    print(\"length of df:\",len(df))\n",
    "    newhaspi0=[]\n",
    "    #loop through data frames\n",
    "    for x in range(len(df)):\n",
    "#         if (x % 10000 == 0):\n",
    "#             print(x)\n",
    "        df_run = df['run'].values[x]\n",
    "        df_subrun = df['subrun'].values[x]\n",
    "        df_event = df['event'].values[x]\n",
    "        df_Enutrue= df['Enu_true'].values[x]\n",
    "        found = False;\n",
    "        if (df['_pi0mass'].values[x] >0):\n",
    "            for i in range(len(run_list)):\n",
    "                if found ==False:\n",
    "                    truth_run = run_list[i]\n",
    "                    truth_subrun = subrun_list[i]\n",
    "                    truth_event = event_list[i]\n",
    "                    # check to see if json entry matches df entry\n",
    "                    if (truth_run ==df_run and truth_subrun ==df_subrun and truth_event ==df_event ):\n",
    "                        if (run2==False):\n",
    "                            found = True\n",
    "                        elif (run2==True):\n",
    "                            if(abs(df_Enutrue - energy_list[i])<2.0):\n",
    "                                found = True\n",
    "                                \n",
    "                            \n",
    "\n",
    "        if found==True:\n",
    "            newhaspi0.append(1)\n",
    "        else:\n",
    "            newhaspi0.append(0)\n",
    "    print(\"length of output:\",len(newhaspi0))\n",
    "    return newhaspi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run1pi0 = newhaspi0flag(df_numu_goodruns_pmtprecut,run_mu_1,subrun_mu_1,event_mu_1)\n",
    "# run1pi0_1mil = newhaspi0flag(df_numu_goodruns_pmtprecut_1Mil,run_mu_1_1mil,subrun_mu_1_1mil,event_mu_1_1mil)\n",
    "# # run2pi0 = newhaspi0flag(df_numu_r2_goodruns_pmtprecut,run_mu_2,subrun_mu_2,event_mu_2,enu_true_mu_2,True)\n",
    "# run2pi0_1mil = newhaspi0flag(df_numu_r2_goodruns_pmtprecut_1Mil,run_mu_2_1mil,subrun_mu_2_1mil,event_mu_2_1mil,True)\n",
    "# run3pi0 = newhaspi0flag(df_numu_r3_goodruns_pmtprecut,run_mu_3,subrun_mu_3,event_mu_3)\n",
    "\n",
    "# # df_numu_goodruns_pmtprecut[\"newhaspi0\"] = run1pi0\n",
    "# df_numu_goodruns_pmtprecut_1Mil[\"newhaspi0\"] = run1pi0_1mil\n",
    "# # df_numu_r2_goodruns_pmtprecut[\"newhaspi0\"] = run2pi0\n",
    "# df_numu_r2_goodruns_pmtprecut_1Mil[\"newhaspi0\"] = run2pi0_1mil\n",
    "# df_numu_r3_goodruns_pmtprecut[\"newhaspi0\"] = run3pi0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new shower energies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showerE_v2(df):\n",
    "    energy1 = []\n",
    "    energy2 = []\n",
    "    currentslope = 0.013456\n",
    "    currentbias = 2.06955\n",
    "    for idx in range(len(df)):\n",
    "        oldE1 = df['shower1_E_Y'].values[idx]\n",
    "        oldE2 = df['shower2_E_Y'].values[idx]\n",
    "        A1 = (oldE1-currentbias)/currentslope\n",
    "        A2 = (oldE2-currentbias)/currentslope\n",
    "        energy1.append(A1*0.01255796)\n",
    "        energy2.append(A2*0.01255796)\n",
    "    return energy1, energy2\n",
    "\n",
    "for df in df_list:\n",
    "    E1,E2 = showerE_v2(df)\n",
    "    df['shower1_E_Y_new'] = E1\n",
    "    df['shower2_E_Y_new'] = E2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delta mass reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions work on individual df\n",
    "\n",
    "def gamma4vectorshower1(df,energy_v):\n",
    "    allvectors = []\n",
    "    for idx in range(0,len(df)):\n",
    "        energy = energy_v[idx]\n",
    "        xdir = df['shower1_dir_3d_X'].values[idx]\n",
    "        ydir = df['shower1_dir_3d_Y'].values[idx]\n",
    "        zdir = df['shower1_dir_3d_Z'].values[idx]\n",
    "        #check magnitude\n",
    "        mag = sqrt(xdir*xdir+ydir*ydir+zdir*zdir)\n",
    "        if (mag != 0):\n",
    "            singlevector = [energy,(xdir/mag)*energy,(ydir/mag)*energy,(zdir/mag)*energy]\n",
    "        else:\n",
    "            singlevector = [-9999,-9999,-9999,-9999]\n",
    "        allvectors.append(singlevector)\n",
    "    return allvectors\n",
    "\n",
    "def gamma4vectorshower2(df,energy_v):\n",
    "    allvectors = []\n",
    "    for idx in range(0,len(df)):\n",
    "        energy = energy_v[idx]\n",
    "        xdir = df['shower2_dir_3d_X'].values[idx]\n",
    "        ydir = df['shower2_dir_3d_Y'].values[idx]\n",
    "        zdir = df['shower2_dir_3d_Z'].values[idx]\n",
    "        #check magnitude\n",
    "        mag = sqrt(xdir*xdir+ydir*ydir+zdir*zdir)\n",
    "        if (mag != 0):\n",
    "            singlevector = [energy,(xdir/mag)*energy,(ydir/mag)*energy,(zdir/mag)*energy]\n",
    "        else:\n",
    "            singlevector = [-9999,-9999,-9999,-9999]\n",
    "        allvectors.append(singlevector)\n",
    "    return allvectors\n",
    "\n",
    "# now turn them into pi0 vectors\n",
    "def pi04vector(shower1,shower2):\n",
    "    allvectors = []\n",
    "    for evt in range(len(shower1)):\n",
    "        shower1_v = shower1[evt]\n",
    "        shower2_v = shower2[evt]\n",
    "        if(shower1_v[0] > -9999 and shower1_v[0] > -9999):\n",
    "            singlevector = [shower1_v[0]+shower2_v[0],shower1_v[1]+shower2_v[1],shower1_v[2]+shower2_v[2],shower1_v[3]+shower2_v[3]]\n",
    "        else:\n",
    "            singlevector = [-9999,-9999,-9999,-9999]\n",
    "        allvectors.append(singlevector)\n",
    "    return allvectors\n",
    "\n",
    "# make proton 4 vector\n",
    "def proton4vector(df):\n",
    "    allvectors = []\n",
    "    for idx in range(0,len(df)):\n",
    "        energy = df['Proton_Edep'].values[idx]+938\n",
    "        momentum = 0\n",
    "        if (energy>0):\n",
    "            momentum = sqrt(energy*energy -(938*938))\n",
    "        theta = df['Proton_ThetaReco'].values[idx]\n",
    "        phi = df['Proton_PhiReco'].values[idx]\n",
    "        xdir = sin(theta)*cos(phi)\n",
    "        ydir = sin(theta)*sin(phi)\n",
    "        zdir = cos(theta)\n",
    "        #check magnitude\n",
    "        mag = sqrt(xdir*xdir+ydir*ydir+zdir*zdir)\n",
    "        singlevector = [energy,(xdir/mag)*momentum,(ydir/mag)*momentum,(zdir/mag)*momentum]\n",
    "        allvectors.append(singlevector)\n",
    "    return allvectors\n",
    "\n",
    "def delta4vector(proton,pi0):\n",
    "    allvectors = []\n",
    "    for evt in range(len(proton)):\n",
    "        energy = proton[evt][0]+pi0[evt][0]\n",
    "        momx = proton[evt][1]+pi0[evt][1]\n",
    "        momy = proton[evt][2]+pi0[evt][2]\n",
    "        momz = proton[evt][3]+pi0[evt][3]\n",
    "        if (pi0[evt][0] >-9999):\n",
    "            singlevector = [energy,momx,momy,momz]\n",
    "        else:\n",
    "            singlevector = [-9999,-9999,-9999,-9999]\n",
    "        allvectors.append(singlevector)\n",
    "    return allvectors\n",
    "\n",
    "# get delta rest mass\n",
    "\n",
    "def deltarestmass(delta):\n",
    "    restmass = 0\n",
    "    mass_v=[]\n",
    "    for evt in range(len(delta)):\n",
    "        energy = delta[evt][0]\n",
    "        momx = delta[evt][1]\n",
    "        momy = delta[evt][2]\n",
    "        momz = delta[evt][3]\n",
    "        mom = 0\n",
    "        if (momx >0 or momy>0 or momz>0):\n",
    "            mom = sqrt(momx*momx+momy*momy+momz*momz)\n",
    "        if (energy >-9999):\n",
    "            mass = sqrt(energy*energy-mom*mom)\n",
    "        else:\n",
    "            mass = -9999\n",
    "        mass_v.append(mass)\n",
    "    return mass_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run through each dataframe\n",
    "for df in df_list:\n",
    "    shower1 = gamma4vectorshower1(df,df['shower1_E_Y'].values)\n",
    "    shower2 = gamma4vectorshower2(df,df['shower2_E_Y'].values)\n",
    "    pi0 = pi04vector(shower1,shower2)\n",
    "    proton = proton4vector(df)\n",
    "    delta = delta4vector(proton,pi0)\n",
    "    mass = deltarestmass(delta)\n",
    "    df['DeltaMass'] = mass\n",
    "\n",
    "for df in df_list:\n",
    "    shower1 = gamma4vectorshower1(df,df['shower1_E_Y_new'].values)\n",
    "    shower2 = gamma4vectorshower2(df,df['shower2_E_Y_new'].values)\n",
    "    pi0 = pi04vector(shower1,shower2)\n",
    "    proton = proton4vector(df)\n",
    "    delta = delta4vector(proton,pi0)\n",
    "    mass = deltarestmass(delta)\n",
    "    df['DeltaMass_new'] = mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new pi0 mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi0mass_v2(df):\n",
    "    mass_v=[]\n",
    "    for idx in range(len(df)):\n",
    "        oldm = df['_pi0mass'].values[idx]\n",
    "        if oldm >0:\n",
    "            E1 = df['shower1_E_Y_new'].values[idx]\n",
    "            E2 = df['shower2_E_Y_new'].values[idx]\n",
    "            alpha = df[\"_shower_alpha\"].values[idx]\n",
    "            C = 4*sin(alpha/2.0)*sin(alpha/2.0)\n",
    "            newmass = sqrt(C*E1*E2)\n",
    "        else:\n",
    "            newmass = oldm\n",
    "        \n",
    "        mass_v.append(newmass)\n",
    "   \n",
    "    return mass_v\n",
    "\n",
    "for df in df_list:\n",
    "    newm = pi0mass_v2(df)\n",
    "    df['_pi0mass_new'] = newm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPID g/e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ge(df):\n",
    "    ge  = []\n",
    "    ge_norm = []\n",
    "    muon= []\n",
    "    \n",
    "    for idx in range(0,len(df)):\n",
    "        g = df['GammaPID_pix_v'].values[idx][2]\n",
    "        e = df['EminusPID_pix_v'].values[idx][2]\n",
    "        muon.append(df['MuonPID_pix_v'].values[idx][2])\n",
    "        if e>0:\n",
    "            ge.append(np.log(g/e))\n",
    "            ge_norm.append(g/(e+g))\n",
    "        else:\n",
    "            ge.append(-1.0)\n",
    "            ge_norm.append(-1.0)\n",
    "        \n",
    "    \n",
    "    return ge,ge_norm,muon\n",
    "\n",
    "for df in df_list:\n",
    "    ge,ge_norm,muon= get_ge(df)\n",
    "    df['MPID_ge'] = ge\n",
    "    df['MPID_ge_norm']= ge_norm\n",
    "    df['MPID_muon']= muon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPF Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcos(df,varname):\n",
    "    cos_val = []\n",
    "    for idx in range(0,len(df)):\n",
    "        ang = df[varname].values[idx]\n",
    "        cos_val.append(np.cos(ang))\n",
    "    return cos_val\n",
    "\n",
    "for df in df_list:\n",
    "    cos_val_l = getcos(df,'Lepton_ThetaReco')\n",
    "    cos_val_p = getcos(df,'Proton_ThetaReco')\n",
    "    df['Lepton_CosTheta'] = cos_val_l\n",
    "    df['Proton_CosTheta'] = cos_val_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pi0 momentum and energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate energy\n",
    "#load in json files with truth info...\n",
    "f_bnb_run1= open(\"../data/truthvariables_bnb_overlay_run1.json\", \"r\")\n",
    "truthdata_bnb_r1 = json.load(f_bnb_run1)\n",
    "f_bnb_run2= open(\"../data/truthvariables_bnb_overlay_run2.json\", \"r\")\n",
    "truthdata_bnb_r2 = json.load(f_bnb_run2)\n",
    "f_bnb_run3= open(\"../data/truthvariables_bnb_overlay_run3.json\", \"r\")\n",
    "truthdata_bnb_r3 = json.load(f_bnb_run3)\n",
    "\n",
    "f_bnb_run1_1mil_1= open(\"../data/truthvariables_numu1_1mil_1.json\", \"r\")\n",
    "truthdata_bnb_run1_1mil_1 = json.load(f_bnb_run1_1mil_1)\n",
    "f_bnb_run1_1mil_2= open(\"../data/truthvariables_numu1_1mil_2.json\", \"r\")\n",
    "truthdata_bnb_run1_1mil_2 = json.load(f_bnb_run1_1mil_2)\n",
    "f_bnb_run2_1mil_1= open(\"../data/truthvariables_numu2_1mil_1.json\", \"r\")\n",
    "truthdata_bnb_run2_1mil_1 = json.load(f_bnb_run2_1mil_1)\n",
    "f_bnb_run2_1mil_2= open(\"../data/truthvariables_numu2_1mil_2.json\", \"r\")\n",
    "truthdata_bnb_run2_1mil_2 = json.load(f_bnb_run2_1mil_2)\n",
    "\n",
    "\n",
    "f_nue_run1= open(\"../data/truthvariables_nue_intrinsics_run1.json\", \"r\")\n",
    "truthdata_nue_r1 = json.load(f_nue_run1)\n",
    "f_nue_run2= open(\"../data/truthvariables_nue_intrinsics_run2.json\", \"r\")\n",
    "truthdata_nue_r2 = json.load(f_nue_run2)\n",
    "f_nue_run3= open(\"../data/truthvariables_nue_intrinsics_run3.json\", \"r\")\n",
    "truthdata_nue_r3 = json.load(f_nue_run3)\n",
    "\n",
    "f_ccpi0_run1 = open(\"../data/truthvariables_ccpi0_run1.json\", \"r\")\n",
    "truthdata_ccpi0_r1 =json.load(f_ccpi0_run1)\n",
    "f_ccpi0_run3 = open(\"../data/truthvariables_ccpi0_run3.json\", \"r\")\n",
    "truthdata_ccpi0_r3 =json.load(f_ccpi0_run3)\n",
    "f_ncpi0_run1 = open(\"../data/truthvariables_ncpi0_run1.json\", \"r\")\n",
    "truthdata_ncpi0_r1 =json.load(f_ncpi0_run1)\n",
    "f_ncpi0_run3a = open(\"../data/truthvariables_ncpi0_run3a.json\", \"r\")\n",
    "truthdata_ncpi0_r3a =json.load(f_ncpi0_run3a)\n",
    "f_ncpi0_run3b = open(\"../data/truthvariables_ncpi0_run3b.json\", \"r\")\n",
    "truthdata_ncpi0_r3b =json.load(f_ncpi0_run3b)\n",
    "\n",
    "# define functions to fill data frames\n",
    "def truePi0(df,truthdata,pi0sample=False,islarge=False,truthdata2=[]):\n",
    "    print(len(df))\n",
    "    #get the true pi0 variables from the json info files\n",
    "    var_e = []\n",
    "    var_p = []\n",
    "    var_px = []\n",
    "    var_py = []\n",
    "    var_pz = []\n",
    "    gamma_1 =[]\n",
    "    gamma_2 = []\n",
    "\n",
    "    for x in range(len(df)):\n",
    "        if (x % 10000 == 0):\n",
    "            print(x)\n",
    "        df_run = df['run'].values[x]\n",
    "        df_subrun = df['subrun'].values[x]\n",
    "        df_event = df['event'].values[x]\n",
    "        found = False;\n",
    "        if (df['haspi0'].values[x] ==1):\n",
    "#         if (df['haspi0'].values[x] ==1 and df['_pi0mass'].values[x] >0):\n",
    "            for i in range(len(truthdata[\"entries\"])):\n",
    "                if found ==False:\n",
    "                    truth_run = truthdata[\"entries\"][i][\"run\"]\n",
    "                    truth_subrun = truthdata[\"entries\"][i][\"subrun\"]\n",
    "                    truth_event = truthdata[\"entries\"][i][\"event\"]\n",
    "                    # check to see if json entry matches df entry\n",
    "                    if (truth_run ==df_run and truth_subrun ==df_subrun and truth_event ==df_event ):\n",
    "                        found = True\n",
    "                        foundpi0 = False\n",
    "\n",
    "                        # loop through particles and  search for a pi0\n",
    "                        for part in range(len(truthdata[\"entries\"][i]['particle_pdg'])):\n",
    "                            pdg = truthdata[\"entries\"][i]['particle_pdg'][part]\n",
    "                            if (pdg == 111):\n",
    "                                if foundpi0 ==False:\n",
    "                                    var_e.append(truthdata[\"entries\"][i]['particle_Energy'][part]*1000.0)\n",
    "                                    px= truthdata[\"entries\"][i]['particle_Px'][part]*1000.0\n",
    "                                    py= truthdata[\"entries\"][i]['particle_Py'][part]*1000.0\n",
    "                                    pz=truthdata[\"entries\"][i]['particle_Pz'][part]*1000.0\n",
    "                                    ptot = sqrt(px**2+py**2+pz**2)\n",
    "                                    var_p.append(ptot)\n",
    "                                    var_px.append(px)\n",
    "                                    var_py.append(py)\n",
    "                                    var_pz.append(pz)\n",
    "#                                     if it is from the pi0 sample, we also have true gamma energy \n",
    "                                    if pi0sample==True:\n",
    "                                        gamma_1.append(truthdata[\"entries\"][i]['gamma_E_true'][0])\n",
    "                                        gamma_2.append(truthdata[\"entries\"][i]['gamma_E_true'][1])\n",
    "                                foundpi0= True\n",
    "                        if foundpi0 ==False:\n",
    "                            var_e.append(-999)\n",
    "                            var_p.append(-999)\n",
    "                            var_px.append(-999)\n",
    "                            var_py.append(-999)\n",
    "                            var_pz.append(-999)\n",
    "                            gamma_1.append(-999)\n",
    "                            gamma_2.append(-999)\n",
    "            \n",
    "            if (islarge ==True and found==False): \n",
    "                for i in range(len(truthdata2[\"entries\"])):\n",
    "                    if found ==False:\n",
    "                        truth_run = truthdata2[\"entries\"][i][\"run\"]\n",
    "                        truth_subrun = truthdata2[\"entries\"][i][\"subrun\"]\n",
    "                        truth_event = truthdata2[\"entries\"][i][\"event\"]\n",
    "                        # check to see if json entry matches df entry\n",
    "                        if (truth_run ==df_run and truth_subrun ==df_subrun and truth_event ==df_event ):\n",
    "                            found = True\n",
    "                            foundpi0 = False\n",
    "\n",
    "                            # loop through particles and  search for a pi0\n",
    "                            for part in range(len(truthdata2[\"entries\"][i]['particle_pdg'])):\n",
    "                                pdg = truthdata2[\"entries\"][i]['particle_pdg'][part]\n",
    "                                if (pdg == 111):\n",
    "                                    if foundpi0 ==False:\n",
    "                                        var_e.append(truthdata2[\"entries\"][i]['particle_Energy'][part]*1000.0)\n",
    "                                        px= truthdata2[\"entries\"][i]['particle_Px'][part]*1000.0\n",
    "                                        py= truthdata2[\"entries\"][i]['particle_Py'][part]*1000.0\n",
    "                                        pz=truthdata2[\"entries\"][i]['particle_Pz'][part]*1000.0\n",
    "                                        ptot = sqrt(px**2+py**2+pz**2)\n",
    "                                        var_p.append(ptot)\n",
    "                                        var_px.append(px)\n",
    "                                        var_py.append(py)\n",
    "                                        var_pz.append(pz)\n",
    "    #                                     if it is from the pi0 sample, we also have true gamma energy \n",
    "                                        if pi0sample==True:\n",
    "                                            gamma_1.append(truthdata2[\"entries\"][i]['gamma_E_true'][0])\n",
    "                                            gamma_2.append(truthdata2[\"entries\"][i]['gamma_E_true'][1])\n",
    "                                            print(truthdata1[\"entries\"][i]['gamma_E_true'][0],truthdata2[\"entries\"][i]['gamma_E_true'][0])\n",
    "                                    foundpi0= True\n",
    "                            if foundpi0 ==False:\n",
    "                                var_e.append(-999)\n",
    "                                var_p.append(-999)\n",
    "                                var_px.append(-999)\n",
    "                                var_py.append(-999)\n",
    "                                var_pz.append(-999)\n",
    "                                gamma_1.append(-999)\n",
    "                                gamma_2.append(-999)\n",
    "                        \n",
    "        if found == False:\n",
    "            var_e.append(-9999)\n",
    "            var_p.append(-9999)\n",
    "            var_px.append(-9999)\n",
    "            var_py.append(-9999)\n",
    "            var_pz.append(-9999)\n",
    "            gamma_1.append(-999)\n",
    "            gamma_2.append(-999)\n",
    "            \n",
    "    return var_e,var_p,var_px,var_py,var_pz,gamma_1,gamma_2\n",
    "\n",
    "\n",
    "\n",
    "def recomomentum(df):\n",
    "    momentum_v = []\n",
    "    for x in range(0,len(df)):\n",
    "        E1 = df[\"shower1_E_Y\"].values[x]\n",
    "        E2 = df[\"shower2_E_Y\"].values[x]\n",
    "        x1 = df['shower1_dir_3d_X'].values[x]\n",
    "        y1 = df['shower1_dir_3d_Y'].values[x]\n",
    "        z1 = df['shower1_dir_3d_Z'].values[x]\n",
    "        x2 = df['shower2_dir_3d_X'].values[x]\n",
    "        y2 = df['shower2_dir_3d_Y'].values[x]\n",
    "        z2 = df['shower2_dir_3d_Z'].values[x]\n",
    "        #check magnitude\n",
    "        mag1 = sqrt(x1*x1+y1*y1+z1*z1)\n",
    "        mag2 = sqrt(x2*x2+y2*y2+z2*z2)\n",
    "        if E1<0 or E2<0 or mag1 <=0 or mag2 <=0:\n",
    "            momentum_v.append(-9999)\n",
    "        else:\n",
    "            singlevector1 = [(x1/mag1)*E1,(y1/mag1)*E1,(z1/mag1)*E1]\n",
    "            singlevector2 = [(x2/mag2)*E2,(y2/mag2)*E2,(z2/mag2)*E2]\n",
    "            momentumpi0 = [singlevector1[0]+singlevector2[0],singlevector1[1]+singlevector2[1],singlevector1[2]+singlevector2[2]]\n",
    "            momentum = sqrt(momentumpi0[0]**2+momentumpi0[1]**2+momentumpi0[2]**2)\n",
    "            momentum_v.append(momentum)\n",
    "    return momentum_v\n",
    "\n",
    "def recomomentum_v2(df):\n",
    "    momentum_v = []\n",
    "    for x in range(0,len(df)):\n",
    "        E1 = df[\"shower1_E_Y_new\"].values[x]\n",
    "        E2 = df[\"shower2_E_Y_new\"].values[x]\n",
    "        x1 = df['shower1_dir_3d_X'].values[x]\n",
    "        y1 = df['shower1_dir_3d_Y'].values[x]\n",
    "        z1 = df['shower1_dir_3d_Z'].values[x]\n",
    "        x2 = df['shower2_dir_3d_X'].values[x]\n",
    "        y2 = df['shower2_dir_3d_Y'].values[x]\n",
    "        z2 = df['shower2_dir_3d_Z'].values[x]\n",
    "        #check magnitude\n",
    "        mag1 = sqrt(x1*x1+y1*y1+z1*z1)\n",
    "        mag2 = sqrt(x2*x2+y2*y2+z2*z2)\n",
    "        if E1<0 or E2<0 or mag1 <=0 or mag2 <=0:\n",
    "            momentum_v.append(-9999)\n",
    "        else:\n",
    "            singlevector1 = [(x1/mag1)*E1,(y1/mag1)*E1,(z1/mag1)*E1]\n",
    "            singlevector2 = [(x2/mag2)*E2,(y2/mag2)*E2,(z2/mag2)*E2]\n",
    "            momentumpi0 = [singlevector1[0]+singlevector2[0],singlevector1[1]+singlevector2[1],singlevector1[2]+singlevector2[2]]\n",
    "            momentum = sqrt(momentumpi0[0]**2+momentumpi0[1]**2+momentumpi0[2]**2)\n",
    "            momentum_v.append(momentum)\n",
    "    return momentum_v\n",
    "\n",
    "\n",
    "def recopi0energy(df):\n",
    "    var = []\n",
    "    for x in range(len(df)):\n",
    "        m = df[\"_pi0mass\"].values[x]\n",
    "        E1 = df[\"shower1_E_Y\"].values[x]\n",
    "        E2 = df[\"shower2_E_Y\"].values[x]\n",
    "        theta = df['_shower_alpha'].values[x]\n",
    "        if (m<=0):\n",
    "            var.append(-9999)\n",
    "        else:\n",
    "            alpha = abs(E1-E2)/(E1+E2)\n",
    "            Energy = m*sqrt(2.0/((1-alpha**2)*(1-cos(theta))))\n",
    "            var.append(Energy)\n",
    "    return var\n",
    "\n",
    "def recopi0energy_v2(df):\n",
    "    var = []\n",
    "    for x in range(len(df)):\n",
    "        m = df[\"_pi0mass_new\"].values[x]\n",
    "        E1 = df[\"shower1_E_Y_new\"].values[x]\n",
    "        E2 = df[\"shower2_E_Y_new\"].values[x]\n",
    "        theta = df['_shower_alpha'].values[x]\n",
    "        if (m<=0):\n",
    "            var.append(-9999)\n",
    "        else:\n",
    "            alpha = abs(E1-E2)/(E1+E2)\n",
    "            Energy = m*sqrt(2.0/((1-alpha**2)*(1-cos(theta))))\n",
    "            var.append(Energy)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with jsons\n"
     ]
    }
   ],
   "source": [
    "#  now actually fill the data frames...THIS TAKES A WHILE TO RUN. COMMENT OUT TRUTH IF ONLY UPDATING RECO VARIABLES\n",
    "for df in df_list:\n",
    "    recom= recomomentum(df)\n",
    "    recoenergy = recopi0energy(df)\n",
    "    df['pi0_energy_reco'] = recoenergy\n",
    "    df['pi0_momentum_reco'] = recom\n",
    "    recom2= recomomentum_v2(df)\n",
    "    recoenergy2 = recopi0energy_v2(df)\n",
    "    df['pi0_energy_reco_new'] = recoenergy2\n",
    "    df['pi0_momentum_reco_new'] = recom2\n",
    "\n",
    "# trueE_bnb1,trueP_bnb1,truePx_bnb1,truePy_bnb1,truePz_bnb1,g1_bnb1,g2_bnb1= truePi0(df_numu_goodruns_pmtprecut,truthdata_bnb_r1)\n",
    "# print(\"run1bnb done\")\n",
    "# trueE_bnb1_1mil,trueP_bnb1_1mil,truePx_bnb1_1mil,truePy_bnb1_1mil,truePz_bnb1_1mil,g1_bnb_1mil,g2_bnb_1mil = truePi0(df_numu_goodruns_pmtprecut_1Mil,truthdata_bnb_run1_1mil_1,False,True,truthdata_bnb_run1_1mil_2)\n",
    "# print(\"run1bnb 1Mil done\")\n",
    "# trueE_bnb2,trueP_bnb2,truePx_bnb2,truePy_bnb2,truePz_bnb2,g1_bnb2,g2_bnb2 = truePi0(df_numu_r2_goodruns_pmtprecut,truthdata_bnb_r2)\n",
    "# print(\"run2bnb done\")\n",
    "# trueE_bnb2_1mil,trueP_bnb2_1mil,truePx_bnb2_1mil,truePy_bnb2_1mil,truePz_bnb2_1mil,g1_bnb2_1mil,g2_bnb2_1mil= truePi0(df_numu_r2_goodruns_pmtprecut_1Mil,truthdata_bnb_run2_1mil_1,False,True,truthdata_bnb_run2_1mil_2)\n",
    "# print(\"run2bnb 1Mil done\")\n",
    "# trueE_bnb3,trueP_bnb3,truePx_bnb3,truePy_bnb3,truePz_bnb3,g1_bnb3,g2_bnb3 = truePi0(df_numu_r3_goodruns_pmtprecut,truthdata_bnb_r3)\n",
    "# print(\"run3bnb done\")\n",
    "# trueE_nue1,trueP_nue1,truePx_nue1,truePy_nue1,truePz_nue1,g1_nue1,g2_nue1 = truePi0(df_nue_goodruns_pmtprecut,truthdata_nue_r1)\n",
    "# print(\"run1nue done\")\n",
    "# trueE_nue2,trueP_nue2,truePx_nue2,truePy_nue2,truePz_nue2,g1_nue2,g2_nue2 = truePi0(df_nue_r2_goodruns_pmtprecut,truthdata_nue_r2)\n",
    "# print(\"run2nue done\")\n",
    "# trueE_nue3,trueP_nue3,truePx_nue3,truePy_nue3,truePz_nue3,g1_nue3,g2_nue3 = truePi0(df_nue_r3_goodruns_pmtprecut,truthdata_nue_r3)\n",
    "# print(\"run3nue done\")\n",
    "\n",
    "# trueE_ccpi01,trueP_ccpi01,truePx_ccpi01,truePy_ccpi01,truePz_ccpi01,g1_ccpi01,g2_ccpi01 = truePi0(df_ccpi0_r1_goodruns_pmtprecut,truthdata_ccpi0_r1,True)\n",
    "# print(\"run1 ccpi0 done\")\n",
    "# trueE_ccpi03,trueP_ccpi03,truePx_ccpi03,truePy_ccpi03,truePz_ccpi03,g1_ccpi03,g2_ccpi03 = truePi0(df_ccpi0_r3_goodruns_pmtprecut,truthdata_ccpi0_r3,True)\n",
    "# print(\"run3 ccpi0 done\")\n",
    "# trueE_ncpi01,trueP_ncpi01,truePx_ncpi01,truePy_ncpi01,truePz_ncpi01,g1_ncpi01,g2_ncpi01 = truePi0(df_ncpi0_r1_goodruns_pmtprecut,truthdata_ncpi0_r1,True)\n",
    "# print(\"run1 ncpi0 done\")\n",
    "\n",
    "# df_ncpi0_r1_goodruns_pmtprecut['pi0_energy_true'] = trueE_ncpi01\n",
    "# df_ncpi0_r1_goodruns_pmtprecut['pi0_momentum_true']= trueP_ncpi01\n",
    "# df_ncpi0_r1_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_ncpi01\n",
    "# df_ncpi0_r1_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_ncpi01\n",
    "# df_ncpi0_r1_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_ncpi01\n",
    "# df_ncpi0_r1_goodruns_pmtprecut['gamma_1_true']= g1_ncpi01\n",
    "# df_ncpi0_r1_goodruns_pmtprecut['gamma_2_true']= g2_ncpi01\n",
    "\n",
    "# trueE_ncpi03,trueP_ncpi03,truePx_ncpi03,truePy_ncpi03,truePz_ncpi03,g1_ncpi03,g2_ncpi03 = truePi0(df_ncpi0_r3_goodruns_pmtprecut,truthdata_ncpi0_r3a,True,True,truthdata_ncpi0_r3b)\n",
    "# print(\"run3 ncpi0 done\")\n",
    "# trueE_ncpi03b,trueP_ncpi03b,truePx_ncpi03b,truePy_ncpi03b,truePz_ncpi03b,g1_ncpi03b,g2_ncpi03b= truePi0(df_ncpi0_r3b_goodruns_pmtprecut,truthdata_ncpi0_r3b,True)\n",
    "# print(\"run3b ncpi0 done\")\n",
    "\n",
    "# df_numu_goodruns_pmtprecut['pi0_energy_true'] = trueE_bnb1\n",
    "# df_numu_goodruns_pmtprecut['pi0_momentum_true']= trueP_bnb1\n",
    "# df_numu_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_bnb1\n",
    "# df_numu_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_bnb1\n",
    "# df_numu_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_bnb1\n",
    "# df_numu_goodruns_pmtprecut['gamma_1_true']= g1_bnb1\n",
    "# df_numu_goodruns_pmtprecut['gamma_2_true']= g2_bnb1\n",
    "\n",
    "# df_numu_goodruns_pmtprecut_1Mil['pi0_energy_true'] = trueE_bnb1_1mil\n",
    "# df_numu_goodruns_pmtprecut_1Mil['pi0_momentum_true']= trueP_bnb1_1mil\n",
    "# df_numu_goodruns_pmtprecut_1Mil['pi0_momentum_x_true']= truePx_bnb1_1mil\n",
    "# df_numu_goodruns_pmtprecut_1Mil['pi0_momentum_y_true']= truePy_bnb1_1mil\n",
    "# df_numu_goodruns_pmtprecut_1Mil['pi0_momentum_z_true']= truePz_bnb1_1mil\n",
    "# df_numu_goodruns_pmtprecut_1Mil['gamma_1_true']= g1_bnb_1mil\n",
    "# df_numu_goodruns_pmtprecut_1Mil['gamma_2_true']= g2_bnb_1mil\n",
    "\n",
    "# df_nue_goodruns_pmtprecut['pi0_energy_true'] = trueE_nue1\n",
    "# df_nue_goodruns_pmtprecut['pi0_momentum_true']= trueP_nue1\n",
    "# df_nue_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_nue1\n",
    "# df_nue_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_nue1\n",
    "# df_nue_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_nue1\n",
    "# df_nue_goodruns_pmtprecut['gamma_1_true']= g1_nue1\n",
    "# df_nue_goodruns_pmtprecut['gamma_2_true']= g2_nue1\n",
    "\n",
    "# df_numu_r2_goodruns_pmtprecut['pi0_energy_true'] = trueE_bnb2\n",
    "# df_numu_r2_goodruns_pmtprecut['pi0_momentum_true']= trueP_bnb2\n",
    "# df_numu_r2_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_bnb2\n",
    "# df_numu_r2_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_bnb2\n",
    "# df_numu_r2_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_bnb2\n",
    "# df_numu_r2_goodruns_pmtprecut['gamma_1_true']= g1_bnb2\n",
    "# df_numu_r2_goodruns_pmtprecut['gamma_2_true']= g2_bnb2\n",
    "\n",
    "# df_numu_r2_goodruns_pmtprecut_1Mil['pi0_energy_true'] = trueE_bnb2_1mil\n",
    "# df_numu_r2_goodruns_pmtprecut_1Mil['pi0_momentum_true']= trueP_bnb2_1mil\n",
    "# df_numu_r2_goodruns_pmtprecut_1Mil['pi0_momentum_x_true']= truePx_bnb2_1mil\n",
    "# df_numu_r2_goodruns_pmtprecut_1Mil['pi0_momentum_y_true']= truePy_bnb2_1mil\n",
    "# df_numu_r2_goodruns_pmtprecut_1Mil['pi0_momentum_z_true']= truePz_bnb2_1mil\n",
    "# df_numu_r2_goodruns_pmtprecut_1Mil['gamma_1_true']= g1_bnb2_1mil\n",
    "# df_numu_r2_goodruns_pmtprecut_1Mil['gamma_2_true']= g2_bnb2_1mil\n",
    "\n",
    "# df_nue_r2_goodruns_pmtprecut['pi0_energy_true'] = trueE_nue2\n",
    "# df_nue_r2_goodruns_pmtprecut['pi0_momentum_true']= trueP_nue2\n",
    "# df_nue_r2_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_nue2\n",
    "# df_nue_r2_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_nue2\n",
    "# df_nue_r2_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_nue2\n",
    "# df_nue_r2_goodruns_pmtprecut['gamma_1_true']= g1_nue2\n",
    "# df_nue_r2_goodruns_pmtprecut['gamma_2_true']= g2_nue2\n",
    "\n",
    "# df_numu_r3_goodruns_pmtprecut['pi0_energy_true'] = trueE_bnb3\n",
    "# df_numu_r3_goodruns_pmtprecut['pi0_momentum_true']= trueP_bnb3\n",
    "# df_numu_r3_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_bnb3\n",
    "# df_numu_r3_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_bnb3\n",
    "# df_numu_r3_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_bnb3\n",
    "# df_numu_r3_goodruns_pmtprecut['gamma_1_true']= g1_bnb3\n",
    "# df_numu_r3_goodruns_pmtprecut['gamma_2_true']= g2_bnb3\n",
    "\n",
    "# df_nue_r3_goodruns_pmtprecut['pi0_energy_true'] = trueE_nue3\n",
    "# df_nue_r3_goodruns_pmtprecut['pi0_momentum_true']= trueP_nue3\n",
    "# df_nue_r3_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_nue3\n",
    "# df_nue_r3_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_nue3\n",
    "# df_nue_r3_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_nue3\n",
    "# df_nue_r3_goodruns_pmtprecut['gamma_1_true']= g1_nue3\n",
    "# df_nue_r3_goodruns_pmtprecut['gamma_2_true']= g2_nue3\n",
    "\n",
    "# df_ccpi0_r1_goodruns_pmtprecut['pi0_energy_true'] = trueE_ccpi01\n",
    "# df_ccpi0_r1_goodruns_pmtprecut['pi0_momentum_true']= trueP_ccpi01\n",
    "# df_ccpi0_r1_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_ccpi01\n",
    "# df_ccpi0_r1_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_ccpi01\n",
    "# df_ccpi0_r1_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_ccpi01\n",
    "# df_ccpi0_r1_goodruns_pmtprecut['gamma_1_true']= g1_ccpi01\n",
    "# df_ccpi0_r1_goodruns_pmtprecut['gamma_2_true']= g2_ccpi01\n",
    "\n",
    "# df_ccpi0_r3_goodruns_pmtprecut['pi0_energy_true'] = trueE_ccpi03\n",
    "# df_ccpi0_r3_goodruns_pmtprecut['pi0_momentum_true']= trueP_ccpi03\n",
    "# df_ccpi0_r3_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_ccpi03\n",
    "# df_ccpi0_r3_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_ccpi03\n",
    "# df_ccpi0_r3_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_ccpi03\n",
    "# df_ccpi0_r3_goodruns_pmtprecut['gamma_1_true']= g1_ccpi03\n",
    "# df_ccpi0_r3_goodruns_pmtprecut['gamma_2_true']= g2_ccpi03\n",
    "\n",
    "\n",
    "# df_ncpi0_r3_goodruns_pmtprecut['pi0_energy_true'] = trueE_ncpi03\n",
    "# df_ncpi0_r3_goodruns_pmtprecut['pi0_momentum_true']= trueP_ncpi03\n",
    "# df_ncpi0_r3_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_ncpi03\n",
    "# df_ncpi0_r3_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_ncpi03\n",
    "# df_ncpi0_r3_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_ncpi03\n",
    "# df_ncpi0_r3_goodruns_pmtprecut['gamma_1_true']= g1_ncpi03\n",
    "# df_ncpi0_r3_goodruns_pmtprecut['gamma_2_true']= g2_ncpi03\n",
    "\n",
    "# df_ncpi0_r3b_goodruns_pmtprecut['pi0_energy_true'] = trueE_ncpi03b\n",
    "# df_ncpi0_r3b_goodruns_pmtprecut['pi0_momentum_true']= trueP_ncpi03b\n",
    "# df_ncpi0_r3b_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_ncpi03b\n",
    "# df_ncpi0_r3b_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_ncpi03b\n",
    "# df_ncpi0_r3b_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_ncpi03b\n",
    "# df_ncpi0_r3b_goodruns_pmtprecut['gamma_1_true']= g1_ncpi03b\n",
    "# df_ncpi0_r3b_goodruns_pmtprecut['gamma_2_true']= g2_ncpi03b\n",
    "\n",
    "print(\"done with jsons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make new truth matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # these should only be used for pi0 samples which have  true gamma energy saved\n",
    "\n",
    "# # function to pick the highest true E as leading\n",
    "# def SetLead_true(df):\n",
    "#     lead = []\n",
    "#     sub = []\n",
    "#     for i in range(len(df)):\n",
    "#         g1 = df['gamma_1_true'].values[i]\n",
    "#         g2 = df['gamma_2_true'].values[i]\n",
    "#         if g1 >= g2:\n",
    "#             lead.append(g1)\n",
    "#             sub.append(g2)\n",
    "#         else:\n",
    "#             lead.append(g2)\n",
    "#             sub.append(g1)\n",
    "#     return lead,sub\n",
    "\n",
    "# # function to pick the highest reco E as leading\n",
    "# def SetLead_reco(df):\n",
    "#     lead = []\n",
    "#     sub = []\n",
    "#     for i in range(len(df)):\n",
    "#         g1 = df['shower1_E_Y_new'].values[i]\n",
    "#         g2 = df['shower2_E_Y_new'].values[i]\n",
    "#         if g1 >= g2:\n",
    "#             lead.append(g1)\n",
    "#             sub.append(g2)\n",
    "#         else:\n",
    "#             lead.append(g2)\n",
    "#             sub.append(g1)\n",
    "#     return lead,sub\n",
    "\n",
    "# # function to pick the highest Q as leading\n",
    "# def SetLead_Q(df):\n",
    "#     lead = []\n",
    "#     sub = []\n",
    "#     for i in range(len(df)):\n",
    "#         g1 = df['shower1_sumQ_Y'].values[i]\n",
    "#         g2 = df['shower2_sumQ_Y'].values[i]\n",
    "#         if g1 >= g2:\n",
    "#             lead.append(g1)\n",
    "#             sub.append(g2)\n",
    "#         else:\n",
    "#             lead.append(g2)\n",
    "#             sub.append(g1)\n",
    "#     return lead,sub\n",
    "\n",
    "# # function to get direction values for new def of lead_sub\n",
    "# def Angle_vals_pi0(df):\n",
    "#     lead_recox=[]\n",
    "#     sub_recox=[]\n",
    "#     lead_recoy=[]\n",
    "#     sub_recoy=[]\n",
    "#     lead_recoz=[]\n",
    "#     sub_recoz=[]\n",
    "#     lead_truex=[]\n",
    "#     sub_truex=[]\n",
    "#     lead_truey=[]\n",
    "#     sub_truey=[]\n",
    "#     lead_truez=[]\n",
    "#     sub_truez=[]\n",
    "#     for idx in range(len(df)):\n",
    "#         # get all direction vectors\n",
    "#         true1x = df['first_direction_true_X'].values[idx]\n",
    "#         true1y = df['first_direction_true_Y'].values[idx]\n",
    "#         true1z = df['first_direction_true_Z'].values[idx]\n",
    "#         reco1x = df['shower1_dir_3d_X'].values[idx]\n",
    "#         reco1y = df['shower1_dir_3d_Y'].values[idx]\n",
    "#         reco1z = df['shower1_dir_3d_Z'].values[idx]\n",
    "#         true2x = df['second_direction_true_X'].values[idx]\n",
    "#         true2y = df['second_direction_true_Y'].values[idx]\n",
    "#         true2z = df['second_direction_true_Z'].values[idx]\n",
    "#         reco2x = df['shower2_dir_3d_X'].values[idx]\n",
    "#         reco2y = df['shower2_dir_3d_Y'].values[idx]\n",
    "#         reco2z = df['shower2_dir_3d_Z'].values[idx]\n",
    "#         #check to see if we need to switch matching based off Energy\n",
    "#         trueg1 = df['gamma_1_true'].values[idx]\n",
    "#         trueg2 = df['gamma_2_true'].values[idx]\n",
    "#         recog1 = df['shower1_E_Y_new'].values[idx]\n",
    "#         recog2 = df['shower2_E_Y_new'].values[idx]\n",
    "       \n",
    "#         if(trueg1>trueg2):\n",
    "#             lead_truex=true1x\n",
    "#             lead_truey=true1y\n",
    "#             lead_truez=true1z\n",
    "#             sub_truex=true2x\n",
    "#             sub_truey=true2y\n",
    "#             sub_truez=true2z\n",
    "#         else:\n",
    "#             lead_truex=true2x\n",
    "#             lead_truey=true2y\n",
    "#             lead_truez=true2z\n",
    "#             sub_truex=true1x\n",
    "#             sub_truey=true1y\n",
    "#             sub_truez=true1z\n",
    "        \n",
    "#         if(recog1>recog2):\n",
    "#             lead_recox=reco1x\n",
    "#             lead_recoy=reco1y\n",
    "#             lead_recoz=reco1z\n",
    "#             sub_recox=reco2x\n",
    "#             sub_recoy=reco2y\n",
    "#             sub_recoz=reco2z\n",
    "#         else:\n",
    "#             lead_recox=reco2x\n",
    "#             lead_recoy=reco2y\n",
    "#             lead_recoz=reco2z\n",
    "#             sub_recox=reco1x\n",
    "#             sub_recoy=reco1y\n",
    "#             sub_recoz=reco1z\n",
    "   \n",
    "#     return lead_truex,sub_truex,lead_truey,sub_truey,lead_truez,sub_truez,lead_recox,sub_recox,lead_recoy,sub_recoy,lead_recoz,sub_recoz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fill data frames with new variables\n",
    "# df_pi0_v =[df_ccpi0_r1_goodruns_pmtprecut,df_ccpi0_r3_goodruns_pmtprecut,df_ncpi0_r1_goodruns_pmtprecut,df_ncpi0_r3a_goodruns_pmtprecut,df_ncpi0_r3b_goodruns_pmtprecut]\n",
    "# for df_pi0 in df_list_mc:\n",
    "#     g_lead_true,g_sub_true = SetLead_true(df_pi0)\n",
    "#     g_lead_reco,g_sub_reco = SetLead_reco(df_pi0)\n",
    "#     g_lead_Q,g_sub_Q = SetLead_Q(df_pi0)\n",
    "#     lead_truex,sub_truex,lead_truey,sub_truey,lead_truez,sub_truez,lead_recox,sub_recox,lead_recoy,sub_recoy,lead_recoz,sub_recoz=Angle_vals_pi0(df_pi0)\n",
    "#     df_pi0['gamma_lead_trueE']= g_lead_true\n",
    "#     df_pi0['gamma_sub_trueE']= g_sub_true\n",
    "#     df_pi0['gamma_lead_recoE']= g_lead_reco\n",
    "#     df_pi0['gamma_sub_recoE']= g_sub_reco\n",
    "#     df_pi0['gamma_lead_recoQ']= g_lead_Q\n",
    "#     df_pi0['gamma_sub_recoQ']= g_sub_Q\n",
    "#     df_pi0['gamma_lead_recoX']= lead_recox\n",
    "#     df_pi0['gamma_lead_recoY']= lead_recoy\n",
    "#     df_pi0['gamma_lead_recoZ']= lead_recoz\n",
    "#     df_pi0['gamma_sub_recoX']= sub_recox\n",
    "#     df_pi0['gamma_sub_recoY']= sub_recoy\n",
    "#     df_pi0['gamma_sub_recoZ']= sub_recoz\n",
    "#     df_pi0['gamma_lead_trueX']= lead_truex\n",
    "#     df_pi0['gamma_lead_trueY']= lead_truey\n",
    "#     df_pi0['gamma_lead_trueZ']= lead_truez\n",
    "#     df_pi0['gamma_sub_trueX']= sub_truex\n",
    "#     df_pi0['gamma_sub_trueY']= sub_truey\n",
    "#     df_pi0['gamma_sub_trueZ']= sub_truez\n",
    "    \n",
    "# # did it work?\n",
    "# print(df_ncpi0_r1_goodruns_pmtprecut['gamma_lead_trueE'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resolution variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Angle_3d_1(df):\n",
    "#     cos = []\n",
    "#     for idx in range(len(df)):\n",
    "#         if df['_pi0mass'].values[idx] >0 :\n",
    "#             # calculate the cos 3d angle between two direction vectors\n",
    "#             x1 = df['first_direction_true_X'].values[idx]\n",
    "#             y1 = df['first_direction_true_Y'].values[idx]\n",
    "#             z1 = df['first_direction_true_Z'].values[idx]\n",
    "#             x2 = df['shower1_dir_3d_X'].values[idx]\n",
    "#             y2 = df['shower1_dir_3d_Y'].values[idx]\n",
    "#             z2 = df['shower1_dir_3d_Z'].values[idx]\n",
    "#             mag1 = sqrt(x1*x1+y1*y1+z1*z1)*1.0\n",
    "#             mag2 = sqrt(x2*x2+y2*y2+z2*z2)*1.0\n",
    "#             dot = ((x1*x2)+(y1*y2)+(z1*z2))*1.0\n",
    "#             cosangle = dot/(mag1*mag2)\n",
    "#             cos.append(cosangle)\n",
    "#         else:\n",
    "#             cos.append(-9999)\n",
    "#     return cos\n",
    "\n",
    "# def Angle_3d_2(df):\n",
    "#     cos = []\n",
    "#     for idx in range(len(df)):\n",
    "#         if df['_pi0mass'].values[idx] >0 :\n",
    "#             # calculate the cos 3d angle between two direction vectors\n",
    "#             x1 = df['second_direction_true_X'].values[idx]\n",
    "#             y1 = df['second_direction_true_Y'].values[idx]\n",
    "#             z1 = df['second_direction_true_Z'].values[idx]\n",
    "#             x2 = df['shower2_dir_3d_X'].values[idx]\n",
    "#             y2 = df['shower2_dir_3d_Y'].values[idx]\n",
    "#             z2 = df['shower2_dir_3d_Z'].values[idx]\n",
    "#             mag1 = sqrt(x1*x1+y1*y1+z1*z1)*1.0\n",
    "#             mag2 = sqrt(x2*x2+y2*y2+z2*z2)*1.0\n",
    "#             dot = ((x1*x2)+(y1*y2)+(z1*z2))*1.0\n",
    "#             cosangle = dot/(mag1*mag2)\n",
    "#             cos.append(cosangle)\n",
    "#         else:\n",
    "#             cos.append(-9999)\n",
    "#     return cos\n",
    "\n",
    "# def Energy_1(df):\n",
    "#     energy = []\n",
    "#     for idx in range(len(df)):\n",
    "#         if df['_pi0mass'].values[idx] >0 :\n",
    "#             # calculate the cos 3d angle between two direction vectors\n",
    "#             Er = df['shower1_E_Y_new'].values[idx]\n",
    "#             Et = df['shower_energy_true'].values[idx]\n",
    "        \n",
    "#             energy.append((Er-Et)/Et)\n",
    "#         else:\n",
    "#             energy.append(-9999)\n",
    "#     return energy\n",
    "\n",
    "\n",
    "# def Energy_2(df):\n",
    "#     energy = []\n",
    "#     for idx in range(len(df)):\n",
    "#         if df['_pi0mass'].values[idx] >0 :\n",
    "#             # calculate the cos 3d angle between two direction vectors\n",
    "#             Er = df['shower2_E_Y_new'].values[idx]\n",
    "#             Et = df['secondshower_energy_true'].values[idx]\n",
    "        \n",
    "#             energy.append((Er-Et)/Et)\n",
    "#         else:\n",
    "#             energy.append(-9999)\n",
    "#     return energy\n",
    "\n",
    "# def resmetric(df):\n",
    "# #     idx number = reco,true\n",
    "#     metric_11=[]\n",
    "#     metric_12=[]\n",
    "#     metric_21=[]\n",
    "#     metric_22=[]\n",
    "#     for idx in range(len(df)):\n",
    "#         if df['_pi0mass_new'].values[idx] >0 :\n",
    "# #             energy res\n",
    "#             Ereco1 = df['shower1_E_Y_new'].values[idx]\n",
    "#             Ereco2 = df['shower2_E_Y_new'].values[idx]\n",
    "#             Etrue1 = df['shower_energy_true'].values[idx]\n",
    "#             Etrue2 = df['secondshower_energy_true'].values[idx]\n",
    "#             Eres11=(Ereco1-Etrue1)/Etrue1\n",
    "#             Eres12=(Ereco1-Etrue2)/Etrue2\n",
    "#             Eres21=(Ereco2-Etrue1)/Etrue1\n",
    "#             Eres22=(Ereco2-Etrue2)/Etrue2\n",
    "                \n",
    "            \n",
    "    \n",
    "#     return metric_11, metric_12, metric_21, metric_22\n",
    "\n",
    "\n",
    "# def pi0mom_res(df):\n",
    "#     mom = []\n",
    "#     for idx in range(len(df)):\n",
    "#         if df['_pi0mass'].values[idx] >0 :\n",
    " \n",
    "#             Er = df['pi0_momentum_reco_new'].values[idx]\n",
    "#             Et = df['pi0_momentum_true'].values[idx]\n",
    "        \n",
    "#             mom.append((Er-Et)/Et)\n",
    "#         else:\n",
    "#             mom.append(-9999)\n",
    "#     return mom\n",
    "\n",
    "# def pi0mass_res(df):\n",
    "#     mass = []\n",
    "#     for idx in range(len(df)):\n",
    "#         if df['_pi0mass'].values[idx] >0 :\n",
    "#             Er = df['_pi0mass_new'].values[idx]\n",
    "#             Et = 135.0\n",
    "        \n",
    "#             mass.append((Er-Et)/Et)\n",
    "#         else:\n",
    "#             mass.append(-9999)\n",
    "#     return mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list_mc =[]\n",
    "# df_list_mc.append(df_numu_goodruns_pmtprecut)\n",
    "# df_list_mc.append(df_nue_goodruns_pmtprecut)\n",
    "# df_list_mc.append(df_numu_r2_goodruns_pmtprecut)\n",
    "# df_list_mc.append(df_nue_r2_goodruns_pmtprecut)\n",
    "# df_list_mc.append(df_numu_r3_goodruns_pmtprecut)\n",
    "# df_list_mc.append(df_nue_r3_goodruns_pmtprecut)\n",
    "# df_list_mc.append(df_ccpi0_r1_goodruns_pmtprecut)\n",
    "# df_list_mc.append(df_ccpi0_r3_goodruns_pmtprecut)\n",
    "# df_list_mc.append(df_ncpi0_r1_goodruns_pmtprecut)\n",
    "# df_list_mc.append(df_ncpi0_r3a_goodruns_pmtprecut)\n",
    "# df_list_mc.append(df_ncpi0_r3b_goodruns_pmtprecut)\n",
    "# for df in df_list_mc:\n",
    "#     cos1 = Angle_3d_1(df)\n",
    "#     cos2 = Angle_3d_2(df)\n",
    "#     df['Pi0AngleRes_1'] = cos1\n",
    "#     df['Pi0AngleRes_2'] = cos2\n",
    "\n",
    "# for df in df_list_mc:\n",
    "#     e1 = Energy_1(df)\n",
    "#     e2 = Energy_2(df)\n",
    "#     df['Pi0EnergyRes_1'] = e1\n",
    "#     df['Pi0EnergyRes_2'] = e2\n",
    "\n",
    "# for df in df_list_mc:\n",
    "#     massres = pi0mass_res(df)\n",
    "#     momres = pi0mom_res(df)\n",
    "#     df['Pi0MomentumRes'] = momres\n",
    "#     df['Pi0MassRes'] = massres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Econsit cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmason/.local/lib/python3.5/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  import sys\n",
      "/home/kmason/.local/lib/python3.5/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "def Econsist(df):\n",
    "    const = []\n",
    "    for i in range(len(df)):\n",
    "        EU = df['shower1_sumQ_U'].values[i]*0.0155481\n",
    "        EV = df['shower1_sumQ_V'].values[i]*0.01586385\n",
    "        EY = df['shower1_sumQ_Y'].values[i]*0.01319672      \n",
    "        const.append(sqrt((EU-EV)**2 + (EU-EY)**2 + (EY-EV)**2)/EY)\n",
    "    return const\n",
    "\n",
    "for df in df_list:\n",
    "    const = Econsist(df)\n",
    "    df['Econsit'] = const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write df back to pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numu_goodruns_pmtprecut.to_pickle(pickle_numu_goodruns_pmtprecut)\n",
    "df_numu_goodruns_pmtprecut_1Mil.to_pickle(pickle_numu_goodruns_pmtprecut_1Mil)\n",
    "df_nue_goodruns_pmtprecut.to_pickle(pickle_nue_goodruns_pmtprecut)\n",
    "df_ext_goodruns_pmtprecut.to_pickle(pickle_ext_goodruns_pmtprecut)\n",
    "\n",
    "df_numu_r3_goodruns_pmtprecut.to_pickle(pickle_numu_r3_goodruns_pmtprecut)\n",
    "df_nue_r3_goodruns_pmtprecut.to_pickle(pickle_nue_r3_goodruns_pmtprecut)\n",
    "df_ext_r3_goodruns_pmtprecut.to_pickle(pickle_ext_r3_goodruns_pmtprecut)\n",
    "\n",
    "df_numu_r2_goodruns_pmtprecut.to_pickle(pickle_numu_r2_goodruns_pmtprecut)\n",
    "df_numu_r2_goodruns_pmtprecut_1Mil.to_pickle(pickle_numu_r2_goodruns_pmtprecut_1Mil)\n",
    "df_nue_r2_goodruns_pmtprecut.to_pickle(pickle_nue_r2_goodruns_pmtprecut)\n",
    "\n",
    "df_ccpi0_r1_goodruns_pmtprecut.to_pickle(pickle_ccpi0_r1_goodruns_pmtprecut)\n",
    "df_ccpi0_r3_goodruns_pmtprecut.to_pickle(pickle_ccpi0_r3_goodruns_pmtprecut)\n",
    "df_ncpi0_r1_goodruns_pmtprecut.to_pickle(pickle_ncpi0_r1_goodruns_pmtprecut)\n",
    "df_ncpi0_r3_goodruns_pmtprecut.to_pickle(pickle_ncpi0_r3_goodruns_pmtprecut)\n",
    "# df_ncpi0_r3b_goodruns_pmtprecut.to_pickle(pickle_ncpi0_r3b_goodruns_pmtprecut)\n",
    "\n",
    "# df_data_r1_pi0filter_pmtprecut.to_pickle(pickle_data_r1_pi0filter_pmtprecut)\n",
    "# df_data_r2d_pi0filter_pmtprecut.to_pickle(pickle_data_r2d_pi0filter_pmtprecut)\n",
    "# df_data_r2e_pi0filter_pmtprecut.to_pickle(pickle_data_r2e_pi0filter_pmtprecut)\n",
    "# df_data_r3f_pi0filter_pmtprecut.to_pickle(pickle_data_r3f_pi0filter_pmtprecut)\n",
    "# df_data_r3g_pi0filter_pmtprecut.to_pickle(pickle_data_r3g_pi0filter_pmtprecut)\n",
    "# df_data_r3_open_pmtprecut.to_pickle(pickle_data_r3_open_pmtprecut)\n",
    "df_data_goodruns_pmtprecut.to_pickle(pickle_data_goodruns_pmtprecut)\n",
    "df_data_far_c1_pi0filter_pmtprecut.to_pickle(pickle_data_far_c1_pi0filter_pmtprecut)\n",
    "df_data_far_d2_pi0filter_pmtprecut.to_pickle(pickle_data_far_d2_pi0filter_pmtprecut)\n",
    "df_data_far_e2_pi0filter_pmtprecut.to_pickle(pickle_data_far_e2_pi0filter_pmtprecut)\n",
    "df_data_far_f3_pi0filter_pmtprecut.to_pickle(pickle_data_far_f3_pi0filter_pmtprecut)\n",
    "df_data_far_g3_pi0filter_pmtprecut.to_pickle(pickle_data_far_g3_pi0filter_pmtprecut)\n",
    "\n",
    "# df_fakedata1_goodruns_run1_pmtprecut.to_pickle(pickle_fakedata1_goodruns_run1_pmtprecut)\n",
    "# df_fakedata1_goodruns_run3_pmtprecut.to_pickle(pickle_fakedata1_goodruns_run3_pmtprecut)\n",
    "# df_fakedata2_goodruns_run1_pmtprecut.to_pickle(pickle_fakedata2_goodruns_run1_pmtprecut)\n",
    "# df_fakedata2_goodruns_run3_pmtprecut.to_pickle(pickle_fakedata2_goodruns_run3_pmtprecut)\n",
    "# df_fakedata3_goodruns_run1_pmtprecut.to_pickle(pickle_fakedata3_goodruns_run1_pmtprecut)\n",
    "# df_fakedata3_goodruns_run3_pmtprecut.to_pickle(pickle_fakedata3_goodruns_run3_pmtprecut)\n",
    "# df_fakedata4_goodruns_run1_pmtprecut.to_pickle(pickle_fakedata4_goodruns_run1_pmtprecut)\n",
    "# df_fakedata4_goodruns_run3_pmtprecut.to_pickle(pickle_fakedata4_goodruns_run3_pmtprecut)\n",
    "# df_fakedata5_goodruns_run1_pmtprecut.to_pickle(pickle_fakedata5_goodruns_run1_pmtprecut)\n",
    "# df_fakedata7_goodruns_run1_pmtprecut.to_pickle(pickle_fakedata7_goodruns_run1_pmtprecut)\n",
    "# df_fakedata7_goodruns_run3_pmtprecut.to_pickle(pickle_fakedata7_goodruns_run3_pmtprecut)\n",
    "# print(df_fakedata5_goodruns_run1_pmtprecut['pi0_energy_reco'].values)\n",
    "# numu_wmodX_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_overlay_wiremodX.pkl\")\n",
    "# numu_wmodYZ_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodYZ.pkl\")\n",
    "# numu_thetaXZ_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodThetaXZ.pkl\")\n",
    "# numu_thetaYZ_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodThetaYZ.pkl\")\n",
    "# numu_dedx_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodscaleddedx.pkl\") \n",
    "# numu_SCE_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_SCE.pkl\")\n",
    "# numu_LYdown_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_LYdown.pkl\")\n",
    "# numu_LYR_df.to_pickle(\"/media/disk1/kmason/mcc9_v40_dl_run3b_bnb_nu_overlay_DetVar_LYRayleigh.pkl\")\n",
    "# numu_LYAtt_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_LYAttenuation.pkl\")\n",
    "# numu_recomb_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_recomb2.pkl\")\n",
    "# numu_CV_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_overlay_CV.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
