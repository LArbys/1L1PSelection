{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is code to add new variables to the pickle files for use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2\n",
      "Welcome to JupyROOT 6.14/08\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "%matplotlib inline\n",
    "import platform\n",
    "print(platform.python_version())\n",
    "from ROOT import TFile,vector\n",
    "import ROOT\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from math import sqrt,acos,cos,sin,pi,exp,log,isnan,atan2\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import asarray\n",
    "from root_pandas import read_root\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import asarray as ar,exp\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import LogFormatterMathtext\n",
    "import math\n",
    "import json\n",
    "\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from math import sqrt,acos,cos,sin,pi,exp,log,isnan,atan2\n",
    "from numpy import asarray\n",
    "from root_pandas import read_root\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import quad\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "from textwrap import wrap\n",
    "import copy\n",
    "\n",
    "import seaborn as sns\n",
    "import SupportingFunctions as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 173\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# compat pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 173\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# compat pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/compat/pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fh, encoding, compat, is_verbose)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path, compression)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 177\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 177\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/compat/pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fh, encoding, compat, is_verbose)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 173\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# compat pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 173\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# compat pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/compat/pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fh, encoding, compat, is_verbose)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d3aabcc4da9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mdf_ext_goodruns_pmtprecut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_ext_goodruns_pmtprecut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mdf_data_goodruns_pmtprecut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_data_goodruns_pmtprecut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mdf_numu_r3_goodruns_pmtprecut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_numu_r3_goodruns_pmtprecut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0mdf_nue_r3_goodruns_pmtprecut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_nue_r3_goodruns_pmtprecut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mdf_ext_r3_goodruns_pmtprecut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_ext_r3_goodruns_pmtprecut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path, compression)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 177\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    146\u001b[0m                             is_text=False)\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_f\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 177\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/compat/pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fh, encoding, compat, is_verbose)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load in files - create data frames from pickles\n",
    "tag = 'Nov_6_run1_numu'\n",
    "pickle_numu_goodruns_pmtprecut = ('../data/pickles/numu_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_run1_nue'\n",
    "pickle_nue_goodruns_pmtprecut = ('../data/pickles/nue_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_run1_ext'\n",
    "pickle_ext_goodruns_pmtprecut = ('../data/pickles/ext_goodruns_precuts_%s.pickle'%tag)\n",
    "tag ='Nov_6_open_run1'\n",
    "pickle_data_goodruns_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "\n",
    "# tag = 'May_6_shower_run3'\n",
    "# pickle_data_goodruns_run3_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_run3_ext'\n",
    "pickle_ext_r3_goodruns_pmtprecut = ('../data/pickles/ext_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_run3_numu'\n",
    "pickle_numu_r3_goodruns_pmtprecut = ('../data/pickles/numu_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_run3_nue'\n",
    "pickle_nue_r3_goodruns_pmtprecut = ('../data/pickles/nue_goodruns_precuts_%s.pickle'%tag)\n",
    "\n",
    "tag = 'Nov_6_run2_numu'\n",
    "pickle_numu_r2_goodruns_pmtprecut = ('../data/pickles/numu_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_run2_nue'\n",
    "pickle_nue_r2_goodruns_pmtprecut = ('../data/pickles/nue_goodruns_precuts_%s.pickle'%tag)\n",
    "\n",
    "tag = 'Nov_6_pi0box_run1'\n",
    "pickle_data_r1_pi0filter_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_pi0box_run2D'\n",
    "pickle_data_r2d_pi0filter_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_pi0box_run2E'\n",
    "pickle_data_r2e_pi0filter_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_pi0box_run3F'\n",
    "pickle_data_r3f_pi0filter_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "tag = 'Nov_6_pi0box_run3G'\n",
    "pickle_data_r3g_pi0filter_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "\n",
    "# tag = 'July_30_open_run3'\n",
    "# pickle_data_r3_open_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "\n",
    "# tag = 'Aug_19_fake1_run3'\n",
    "# pickle_fakedata1_goodruns_run3_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Aug_19_fake1_run1'\n",
    "# pickle_fakedata1_goodruns_run1_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Aug_19_fake2_run3'\n",
    "# pickle_fakedata2_goodruns_run3_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Aug_19_fake2_run1'\n",
    "# pickle_fakedata2_goodruns_run1_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Aug_19_fake3_run3'\n",
    "# pickle_fakedata3_goodruns_run3_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Aug_19_fake3_run1'\n",
    "# pickle_fakedata3_goodruns_run1_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Sept_3_fake4_run3'\n",
    "# pickle_fakedata4_goodruns_run3_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Sept_3_fake4_run1'\n",
    "# pickle_fakedata4_goodruns_run1_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "# tag = 'Sept_8_fake5_run1'\n",
    "# pickle_fakedata5_goodruns_run1_pmtprecut = ('../data/pickles/data_goodruns_precuts_%s.pickle'%tag)\n",
    "\n",
    "# detectorvariations\n",
    "# run3_numu_CV = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_overlay_CV.root\"\n",
    "# run3_numu_LYAtt = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_LYAttenuation.root\"\n",
    "# run3_numu_LYRayleigh = \"/media/disk1/kmason/mcc9_v40_dl_run3b_bnb_nu_overlay_DetVar_LYRayleigh.root\"\n",
    "# run3_numu_LYDown = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_LYdown.root\"\n",
    "# run3_numu_Recomb = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_recomb2.root\"\n",
    "# run3_numu_SCE =\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_SCE.root\"\n",
    "# run3_numu_WiremodScaleddEdx = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodscaleddedx.root\"\n",
    "# run3_numu_WiremodThetaXZ = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodThetaXZ.root\"\n",
    "# run3_numu_WiremodThetaYZ = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodThetaYZ.root\"\n",
    "# run3_numu_WiremodYZ = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodYZ.root\"\n",
    "# run3_numu_WiremodX = \"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_overlay_wiremodX.root\"\n",
    "# # numu_CV_df = read_root(run3_numu_CV, 'dlana/FinalVertexVariables')\n",
    "# numu_wmodX_df = read_root(run3_numu_WiremodX, 'dlana/FinalVertexVariables')\n",
    "# numu_wmodYZ_df = read_root(run3_numu_WiremodYZ, 'dlana/FinalVertexVariables')\n",
    "# numu_thetaXZ_df = read_root(run3_numu_WiremodThetaXZ, 'dlana/FinalVertexVariables')\n",
    "# numu_thetaYZ_df = read_root(run3_numu_WiremodThetaYZ, 'dlana/FinalVertexVariables')\n",
    "# numu_dedx_df = read_root(run3_numu_WiremodScaleddEdx, 'dlana/FinalVertexVariables') \n",
    "# numu_SCE_df = read_root(run3_numu_SCE, 'dlana/FinalVertexVariables')\n",
    "# numu_LYdown_df = read_root(run3_numu_LYDown, 'dlana/FinalVertexVariables')\n",
    "# numu_LYR_df = read_root(run3_numu_LYRayleigh, 'dlana/FinalVertexVariables')\n",
    "# numu_LYAtt_df = read_root(run3_numu_LYAtt,'dlana/FinalVertexVariables')\n",
    "# numu_recomb_df = read_root(run3_numu_Recomb,'dlana/FinalVertexVariables')\n",
    "\n",
    "# make data frames\n",
    "# print(pickle_numu_goodruns_pmtprecut)\n",
    "df_numu_goodruns_pmtprecut = pd.read_pickle(pickle_numu_goodruns_pmtprecut)\n",
    "df_nue_goodruns_pmtprecut = pd.read_pickle(pickle_nue_goodruns_pmtprecut)\n",
    "df_ext_goodruns_pmtprecut = pd.read_pickle(pickle_ext_goodruns_pmtprecut)\n",
    "df_data_goodruns_pmtprecut = pd.read_pickle(pickle_data_goodruns_pmtprecut)\n",
    "df_numu_r3_goodruns_pmtprecut = pd.read_pickle(pickle_numu_r3_goodruns_pmtprecut)\n",
    "df_nue_r3_goodruns_pmtprecut = pd.read_pickle(pickle_nue_r3_goodruns_pmtprecut)\n",
    "df_ext_r3_goodruns_pmtprecut = pd.read_pickle(pickle_ext_r3_goodruns_pmtprecut)\n",
    "# df_data_r3_open_pmtprecut = pd.read_pickle(pickle_data_r3_open_pmtprecut)\n",
    "df_numu_r2_goodruns_pmtprecut = pd.read_pickle(pickle_numu_r2_goodruns_pmtprecut)\n",
    "df_nue_r2_goodruns_pmtprecut = pd.read_pickle(pickle_nue_r2_goodruns_pmtprecut)\n",
    "\n",
    "df_data_r1_pi0filter_pmtprecut = pd.read_pickle(pickle_data_r1_pi0filter_pmtprecut)\n",
    "df_data_r2d_pi0filter_pmtprecut = pd.read_pickle(pickle_data_r2d_pi0filter_pmtprecut)\n",
    "df_data_r2e_pi0filter_pmtprecut = pd.read_pickle(pickle_data_r2e_pi0filter_pmtprecut)\n",
    "df_data_r3f_pi0filter_pmtprecut = pd.read_pickle(pickle_data_r3f_pi0filter_pmtprecut)\n",
    "df_data_r3g_pi0filter_pmtprecut = pd.read_pickle(pickle_data_r3g_pi0filter_pmtprecut)\n",
    "\n",
    "\n",
    "# df_fakedata1_goodruns_run3_pmtprecut = pd.read_pickle(pickle_fakedata1_goodruns_run3_pmtprecut)\n",
    "# df_fakedata1_goodruns_run1_pmtprecut = pd.read_pickle(pickle_fakedata1_goodruns_run1_pmtprecut)\n",
    "# df_fakedata2_goodruns_run3_pmtprecut = pd.read_pickle(pickle_fakedata2_goodruns_run3_pmtprecut)\n",
    "# df_fakedata2_goodruns_run1_pmtprecut = pd.read_pickle(pickle_fakedata2_goodruns_run1_pmtprecut)\n",
    "# df_fakedata3_goodruns_run3_pmtprecut = pd.read_pickle(pickle_fakedata3_goodruns_run3_pmtprecut)\n",
    "# df_fakedata3_goodruns_run1_pmtprecut = pd.read_pickle(pickle_fakedata3_goodruns_run1_pmtprecut)\n",
    "# df_fakedata4_goodruns_run3_pmtprecut = pd.read_pickle(pickle_fakedata4_goodruns_run3_pmtprecut)\n",
    "# df_fakedata4_goodruns_run1_pmtprecut = pd.read_pickle(pickle_fakedata4_goodruns_run1_pmtprecut)\n",
    "# df_fakedata5_goodruns_run1_pmtprecut = pd.read_pickle(pickle_fakedata5_goodruns_run1_pmtprecut)\n",
    "\n",
    "# put dataframes in a list for loops\n",
    "df_list=[]\n",
    "df_list_mc=[]\n",
    "df_list_data=[]\n",
    "# df_list = [df_data_r3_open_pmtprecut,df_numu_goodruns_pmtprecut,df_nue_goodruns_pmtprecut,df_ext_goodruns_pmtprecut,df_data_goodruns_pmtprecut,df_numu_r3_goodruns_pmtprecut,df_nue_r3_goodruns_pmtprecut,df_ext_r3_goodruns_pmtprecut, df_fakedata1_goodruns_run3_pmtprecut,df_fakedata1_goodruns_run1_pmtprecut]\n",
    "# df_list_data = [df_data_r3_open_pmtprecut,df_data_goodruns_pmtprecut,df_fakedata1_goodruns_run3_pmtprecut,df_fakedata1_goodruns_run1_pmtprecut]\n",
    "# df_list_mc = [df_numu_goodruns_pmtprecut,df_nue_goodruns_pmtprecut,df_ext_goodruns_pmtprecut,df_numu_r3_goodruns_pmtprecut,df_nue_r3_goodruns_pmtprecut,df_ext_r3_goodruns_pmtprecut]\n",
    "\n",
    "df_list.append(df_data_r1_pi0filter_pmtprecut)\n",
    "df_list.append(df_data_r2d_pi0filter_pmtprecut)\n",
    "df_list.append(df_data_r2e_pi0filter_pmtprecut)\n",
    "df_list.append(df_data_r3f_pi0filter_pmtprecut)\n",
    "df_list.append(df_data_r3g_pi0filter_pmtprecut)\n",
    "df_list.append(df_data_goodruns_pmtprecut)\n",
    "\n",
    "# df_list.append(df_fakedata1_goodruns_run3_pmtprecut)\n",
    "# df_list.append(df_fakedata1_goodruns_run1_pmtprecut)\n",
    "# df_list.append(df_fakedata2_goodruns_run3_pmtprecut)\n",
    "# df_list.append(df_fakedata2_goodruns_run1_pmtprecut)\n",
    "# df_list.append(df_fakedata3_goodruns_run3_pmtprecut)\n",
    "# df_list.append(df_fakedata3_goodruns_run1_pmtprecut)\n",
    "# df_list.append(df_fakedata4_goodruns_run3_pmtprecut)\n",
    "# df_list.append(df_fakedata4_goodruns_run1_pmtprecut)\n",
    "# df_list.append(df_fakedata5_goodruns_run1_pmtprecut)\n",
    "\n",
    "\n",
    "df_list.append(df_numu_goodruns_pmtprecut)\n",
    "df_list.append(df_nue_goodruns_pmtprecut)\n",
    "df_list.append(df_ext_goodruns_pmtprecut)\n",
    "df_list.append(df_numu_r2_goodruns_pmtprecut)\n",
    "df_list.append(df_nue_r2_goodruns_pmtprecut)\n",
    "df_list.append(df_numu_r3_goodruns_pmtprecut)\n",
    "df_list.append(df_nue_r3_goodruns_pmtprecut)\n",
    "df_list.append(df_ext_r3_goodruns_pmtprecut)\n",
    "\n",
    "df_list_data.append(df_data_r1_pi0filter_pmtprecut)\n",
    "df_list_data.append(df_data_r2d_pi0filter_pmtprecut)\n",
    "df_list_data.append(df_data_r2e_pi0filter_pmtprecut)\n",
    "df_list_data.append(df_data_r3f_pi0filter_pmtprecut)\n",
    "df_list_data.append(df_data_r3g_pi0filter_pmtprecut)\n",
    "\n",
    "# df_list_data.append(df_fakedata1_goodruns_run3_pmtprecut)\n",
    "# df_list_data.append(df_fakedata1_goodruns_run1_pmtprecut)\n",
    "# df_list_data.append(df_fakedata2_goodruns_run3_pmtprecut)\n",
    "# df_list_data.append(df_fakedata2_goodruns_run1_pmtprecut)\n",
    "# df_list_data.append(df_fakedata3_goodruns_run3_pmtprecut)\n",
    "# df_list_data.append(df_fakedata3_goodruns_run1_pmtprecut)\n",
    "# df_list_data.append(df_fakedata4_goodruns_run3_pmtprecut)\n",
    "# df_list_data.append(df_fakedata4_goodruns_run1_pmtprecut)\n",
    "# df_list_data.append(df_fakedata5_goodruns_run1_pmtprecut)\n",
    "\n",
    "# # df_list.append(numu_CV_df)\n",
    "# df_list.append(numu_wmodX_df)\n",
    "# df_list.append(numu_wmodYZ_df)\n",
    "# df_list.append(numu_thetaXZ_df)\n",
    "# df_list.append(numu_thetaYZ_df)\n",
    "# df_list.append(numu_dedx_df)\n",
    "# df_list.append(numu_SCE_df)\n",
    "# df_list.append(numu_LYdown_df)\n",
    "# df_list.append(numu_LYR_df)\n",
    "# df_list.append(numu_LYAtt_df)\n",
    "# df_list.append(numu_recomb_df)\n",
    "\n",
    "# # df_list.append(numu_CV_df)\n",
    "# df_list_mc.append(numu_wmodX_df)\n",
    "# df_list_mc.append(numu_wmodYZ_df)\n",
    "# df_list_mc.append(numu_thetaXZ_df)\n",
    "# df_list_mc.append(numu_thetaYZ_df)\n",
    "# df_list_mc.append(numu_dedx_df)\n",
    "# df_list_mc.append(numu_SCE_df)\n",
    "# df_list_mc.append(numu_LYdown_df)\n",
    "# df_list_mc.append(numu_LYR_df)\n",
    "# df_list_mc.append(numu_LYAtt_df)\n",
    "# df_list_mc.append(numu_recomb_df)\n",
    "\n",
    "df_list_mc.append(df_numu_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_nue_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_numu_r2_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_nue_r2_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_numu_r3_goodruns_pmtprecut)\n",
    "df_list_mc.append(df_nue_r3_goodruns_pmtprecut)\n",
    "\n",
    "print(\"loaded everything\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first clear the df if the variables already exist\n",
    "for df in df_list:\n",
    "    if 'DeltaMass' in df.columns:\n",
    "        df.drop('DeltaMass',axis = 1)\n",
    "    if 'Shower1_E_calib' in df.columns:\n",
    "        df.drop('Shower1_E_calib',axis = 1)\n",
    "    if 'Shower2_E_calib' in df.columns:\n",
    "        df.drop('Shower2_E_calib',axis = 1)\n",
    "    if 'pi0mass_calib' in df.columns:\n",
    "        df.drop('pi0mass_calib',axis = 1)\n",
    "    if 'DeltaMass_calib' in df.columns:\n",
    "        df.drop('DeltaMass_calib',axis = 1)\n",
    "    if 'MPID_ge' in df.columns:\n",
    "        df.drop('MPID_ge',axis = 1)   \n",
    "    if 'MPID_ge_norm' in df.columns:\n",
    "        df.drop('MPID_ge_norm',axis = 1)\n",
    "    if 'Pi0Energy_true' in df.columns:\n",
    "        df.drop('Pi0Energy_true',axis = 1)\n",
    "    if 'Pi0Momenutum_true' in df.columns:\n",
    "        df.drop('Pi0Momenutum_true',axis = 1)\n",
    "    if 'Pi0Energy_reco' in df.columns:\n",
    "        df.drop('Pi0Energy_reco',axis = 1)\n",
    "    if 'Pi0Momenutum_reco' in df.columns:\n",
    "        df.drop('Pi0Momenutum_reco',axis = 1)\n",
    "#     if 'pi0_energy_true' in df.columns:\n",
    "#         df.drop('pi0_energy_true',axis = 1)\n",
    "#     if 'pi0_momentum_true' in df.columns:\n",
    "#         df.drop('pi0_momentum_true',axis = 1)\n",
    "#     if 'pi0_momentum_x_true' in df.columns:\n",
    "#         df.drop('pi0_momentum_x_true',axis = 1)\n",
    "#     if 'pi0_momentum_y_true' in df.columns:\n",
    "#         df.drop('pi0_momentum_y_true',axis = 1)\n",
    "#     if 'pi0_momentum_z_true' in df.columns:\n",
    "#         df.drop('pi0_momentum_z_true',axis = 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new shower energies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showerE_v2(df):\n",
    "    energy1 = []\n",
    "    energy2 = []\n",
    "    currentslope = 0.013456\n",
    "    currentbias = 2.06955\n",
    "    for idx in range(len(df)):\n",
    "        oldE1 = df['shower1_E_Y'].values[idx]\n",
    "        oldE2 = df['shower2_E_Y'].values[idx]\n",
    "        A1 = (oldE1-currentbias)/currentslope\n",
    "        A2 = (oldE2-currentbias)/currentslope\n",
    "        energy1.append(A1*0.01319672)\n",
    "        energy2.append(A2*0.01319672)\n",
    "    return energy1, energy2\n",
    "\n",
    "for df in df_list:\n",
    "    E1,E2 = showerE_v2(df)\n",
    "    df['shower1_E_Y_new'] = E1\n",
    "    df['shower2_E_Y_new'] = E2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delta mass reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions work on individual df\n",
    "\n",
    "def gamma4vectorshower1(df,energy_v):\n",
    "    allvectors = []\n",
    "    for idx in range(0,len(df)):\n",
    "        energy = energy_v[idx]\n",
    "        xdir = df['shower1_dir_3d_X'].values[idx]\n",
    "        ydir = df['shower1_dir_3d_Y'].values[idx]\n",
    "        zdir = df['shower1_dir_3d_Z'].values[idx]\n",
    "        #check magnitude\n",
    "        mag = sqrt(xdir*xdir+ydir*ydir+zdir*zdir)\n",
    "        if (mag != 0):\n",
    "            singlevector = [energy,(xdir/mag)*energy,(ydir/mag)*energy,(zdir/mag)*energy]\n",
    "        else:\n",
    "            singlevector = [-9999,-9999,-9999,-9999]\n",
    "        allvectors.append(singlevector)\n",
    "    return allvectors\n",
    "\n",
    "def gamma4vectorshower2(df,energy_v):\n",
    "    allvectors = []\n",
    "    for idx in range(0,len(df)):\n",
    "        energy = energy_v[idx]\n",
    "        xdir = df['shower2_dir_3d_X'].values[idx]\n",
    "        ydir = df['shower2_dir_3d_Y'].values[idx]\n",
    "        zdir = df['shower2_dir_3d_Z'].values[idx]\n",
    "        #check magnitude\n",
    "        mag = sqrt(xdir*xdir+ydir*ydir+zdir*zdir)\n",
    "        if (mag != 0):\n",
    "            singlevector = [energy,(xdir/mag)*energy,(ydir/mag)*energy,(zdir/mag)*energy]\n",
    "        else:\n",
    "            singlevector = [-9999,-9999,-9999,-9999]\n",
    "        allvectors.append(singlevector)\n",
    "    return allvectors\n",
    "\n",
    "# now turn them into pi0 vectors\n",
    "def pi04vector(shower1,shower2):\n",
    "    allvectors = []\n",
    "    for evt in range(len(shower1)):\n",
    "        shower1_v = shower1[evt]\n",
    "        shower2_v = shower2[evt]\n",
    "        if(shower1_v[0] > -9999 and shower1_v[0] > -9999):\n",
    "            singlevector = [shower1_v[0]+shower2_v[0],shower1_v[1]+shower2_v[1],shower1_v[2]+shower2_v[2],shower1_v[3]+shower2_v[3]]\n",
    "        else:\n",
    "            singlevector = [-9999,-9999,-9999,-9999]\n",
    "        allvectors.append(singlevector)\n",
    "    return allvectors\n",
    "\n",
    "# make proton 4 vector\n",
    "def proton4vector(df):\n",
    "    allvectors = []\n",
    "    for idx in range(0,len(df)):\n",
    "        energy = df['Proton_Edep'].values[idx]+938\n",
    "        momentum = 0\n",
    "        if (energy>0):\n",
    "            momentum = sqrt(energy*energy -(938*938))\n",
    "        theta = df['Proton_ThetaReco'].values[idx]\n",
    "        phi = df['Proton_PhiReco'].values[idx]\n",
    "        xdir = sin(theta)*cos(phi)\n",
    "        ydir = sin(theta)*sin(phi)\n",
    "        zdir = cos(theta)\n",
    "        #check magnitude\n",
    "        mag = sqrt(xdir*xdir+ydir*ydir+zdir*zdir)\n",
    "        singlevector = [energy,(xdir/mag)*momentum,(ydir/mag)*momentum,(zdir/mag)*momentum]\n",
    "        allvectors.append(singlevector)\n",
    "    return allvectors\n",
    "\n",
    "def delta4vector(proton,pi0):\n",
    "    allvectors = []\n",
    "    for evt in range(len(proton)):\n",
    "        energy = proton[evt][0]+pi0[evt][0]\n",
    "        momx = proton[evt][1]+pi0[evt][1]\n",
    "        momy = proton[evt][2]+pi0[evt][2]\n",
    "        momz = proton[evt][3]+pi0[evt][3]\n",
    "        if (pi0[evt][0] >-9999):\n",
    "            singlevector = [energy,momx,momy,momz]\n",
    "        else:\n",
    "            singlevector = [-9999,-9999,-9999,-9999]\n",
    "        allvectors.append(singlevector)\n",
    "    return allvectors\n",
    "\n",
    "# get delta rest mass\n",
    "\n",
    "def deltarestmass(delta):\n",
    "    restmass = 0\n",
    "    mass_v=[]\n",
    "    for evt in range(len(delta)):\n",
    "        energy = delta[evt][0]\n",
    "        momx = delta[evt][1]\n",
    "        momy = delta[evt][2]\n",
    "        momz = delta[evt][3]\n",
    "        mom = 0\n",
    "        if (momx >0 or momy>0 or momz>0):\n",
    "            mom = sqrt(momx*momx+momy*momy+momz*momz)\n",
    "        if (energy >-9999):\n",
    "            mass = sqrt(energy*energy-mom*mom)\n",
    "        else:\n",
    "            mass = -9999\n",
    "        mass_v.append(mass)\n",
    "    return mass_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run through each dataframe\n",
    "for df in df_list:\n",
    "    shower1 = gamma4vectorshower1(df,df['shower1_E_Y'].values)\n",
    "    shower2 = gamma4vectorshower2(df,df['shower2_E_Y'].values)\n",
    "    pi0 = pi04vector(shower1,shower2)\n",
    "    proton = proton4vector(df)\n",
    "    delta = delta4vector(proton,pi0)\n",
    "    mass = deltarestmass(delta)\n",
    "    df['DeltaMass'] = mass\n",
    "\n",
    "for df in df_list:\n",
    "    shower1 = gamma4vectorshower1(df,df['shower1_E_Y_new'].values)\n",
    "    shower2 = gamma4vectorshower2(df,df['shower2_E_Y_new'].values)\n",
    "    pi0 = pi04vector(shower1,shower2)\n",
    "    proton = proton4vector(df)\n",
    "    delta = delta4vector(proton,pi0)\n",
    "    mass = deltarestmass(delta)\n",
    "    df['DeltaMass_new'] = mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new pi0 mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi0mass_v2(df):\n",
    "    mass_v=[]\n",
    "    for idx in range(len(df)):\n",
    "        oldm = df['_pi0mass'].values[idx]\n",
    "        if oldm >0:\n",
    "            E1 = df['shower1_E_Y_new'].values[idx]\n",
    "            E2 = df['shower2_E_Y_new'].values[idx]\n",
    "            alpha = df[\"_shower_alpha\"].values[idx]\n",
    "            C = 4*sin(alpha/2.0)*sin(alpha/2.0)\n",
    "            newmass = sqrt(C*E1*E2)\n",
    "        else:\n",
    "            newmass = oldm\n",
    "        \n",
    "        mass_v.append(newmass)\n",
    "   \n",
    "    return mass_v\n",
    "\n",
    "for df in df_list:\n",
    "    newm = pi0mass_v2(df)\n",
    "    df['_pi0mass_new'] = newm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPID g/e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ge(df):\n",
    "    ge  = []\n",
    "    ge_norm = []\n",
    "    muon= []\n",
    "    \n",
    "    for idx in range(0,len(df)):\n",
    "        g = df['GammaPID_pix_v'].values[idx][2]\n",
    "        e = df['EminusPID_pix_v'].values[idx][2]\n",
    "        muon.append(df['MuonPID_pix_v'].values[idx][2])\n",
    "        if e>0:\n",
    "            ge.append(np.log(g/e))\n",
    "            ge_norm.append(g/(e+g))\n",
    "        else:\n",
    "            ge.append(-1.0)\n",
    "            ge_norm.append(-1.0)\n",
    "        \n",
    "    \n",
    "    return ge,ge_norm,muon\n",
    "\n",
    "for df in df_list:\n",
    "    ge,ge_norm,muon= get_ge(df)\n",
    "    df['MPID_ge'] = ge\n",
    "    df['MPID_ge_norm']= ge_norm\n",
    "    df['MPID_muon']= muon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPF Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcos(df,varname):\n",
    "    cos_val = []\n",
    "    for idx in range(0,len(df)):\n",
    "        ang = df[varname].values[idx]\n",
    "        cos_val.append(np.cos(ang))\n",
    "    return cos_val\n",
    "\n",
    "for df in df_list:\n",
    "    cos_val_l = getcos(df,'Lepton_ThetaReco')\n",
    "    cos_val_p = getcos(df,'Proton_ThetaReco')\n",
    "    df['Lepton_CosTheta'] = cos_val_l\n",
    "    df['Proton_CosTheta'] = cos_val_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pi0 momentum and energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate energy\n",
    "#load in json files with truth info...\n",
    "f_bnb_run1= open(\"../data/truthvariables_bnb_overlay_run1.json\", \"r\")\n",
    "truthdata_bnb_r1 = json.load(f_bnb_run1)\n",
    "f_bnb_run2= open(\"../data/truthvariables_bnb_overlay_run2.json\", \"r\")\n",
    "truthdata_bnb_r2 = json.load(f_bnb_run2)\n",
    "f_bnb_run3= open(\"../data/truthvariables_bnb_overlay_run3.json\", \"r\")\n",
    "truthdata_bnb_r3 = json.load(f_bnb_run3)\n",
    "\n",
    "f_nue_run1= open(\"../data/truthvariables_nue_intrinsics_run1.json\", \"r\")\n",
    "truthdata_nue_r1 = json.load(f_nue_run1)\n",
    "f_nue_run2= open(\"../data/truthvariables_nue_intrinsics_run2.json\", \"r\")\n",
    "truthdata_nue_r2 = json.load(f_nue_run2)\n",
    "f_nue_run3= open(\"../data/truthvariables_nue_intrinsics_run3.json\", \"r\")\n",
    "truthdata_nue_r3 = json.load(f_nue_run3)\n",
    "\n",
    "\n",
    "# define functions to fill data frames\n",
    "def truePi0(df,truthdata):\n",
    "    print(len(df))\n",
    "    #get the true pi0 variables from the json info files\n",
    "    var_e = []\n",
    "    var_p = []\n",
    "    var_px = []\n",
    "    var_py = []\n",
    "    var_pz = []\n",
    "\n",
    "    for x in range(len(df)):\n",
    "        if (x % 10000 == 0):\n",
    "            print(x)\n",
    "        df_run = df['run'].values[x]\n",
    "        df_subrun = df['subrun'].values[x]\n",
    "        df_event = df['event'].values[x]\n",
    "        found = False;\n",
    "        if (df['haspi0'].values[x] ==1 and df['_pi0mass'].values[x] >0):\n",
    "            for i in range(len(truthdata[\"entries\"])):\n",
    "                if found ==False:\n",
    "                    truth_run = truthdata[\"entries\"][i][\"run\"]\n",
    "                    truth_subrun = truthdata[\"entries\"][i][\"subrun\"]\n",
    "                    truth_event = truthdata[\"entries\"][i][\"event\"]\n",
    "                    # check to see if json entry matches df entry\n",
    "                    if (truth_run ==df_run and truth_subrun ==df_subrun and truth_event ==df_event ):\n",
    "                        found = True\n",
    "                        foundpi0 = False\n",
    "\n",
    "                        # loop through particles and  search for a pi0\n",
    "                        for part in range(len(truthdata[\"entries\"][i]['particle_pdg'])):\n",
    "                            pdg = truthdata[\"entries\"][i]['particle_pdg'][part]\n",
    "                            if (pdg == 111):\n",
    "                                if foundpi0 ==False:\n",
    "                                    var_e.append(truthdata[\"entries\"][i]['particle_Energy'][part]*1000.0)\n",
    "                                    px= truthdata[\"entries\"][i]['particle_Px'][part]*1000.0\n",
    "                                    py= truthdata[\"entries\"][i]['particle_Py'][part]*1000.0\n",
    "                                    pz=truthdata[\"entries\"][i]['particle_Pz'][part]*1000.0\n",
    "                                    ptot = sqrt(px**2+py**2+pz**2)\n",
    "                                    var_p.append(ptot)\n",
    "                                    var_px.append(px)\n",
    "                                    var_py.append(py)\n",
    "                                    var_pz.append(pz)\n",
    "                                foundpi0= True\n",
    "                        if foundpi0 ==False:\n",
    "                            var_e.append(-999)\n",
    "                            var_p.append(-999)\n",
    "                            var_px.append(-999)\n",
    "                            var_py.append(-999)\n",
    "                            var_pz.append(-999)\n",
    "        if found == False:\n",
    "            var_e.append(-9999)\n",
    "            var_p.append(-9999)\n",
    "            var_px.append(-9999)\n",
    "            var_py.append(-9999)\n",
    "            var_pz.append(-9999)\n",
    "            \n",
    "    return var_e,var_p,var_px,var_py,var_pz\n",
    "\n",
    "\n",
    "\n",
    "def recomomentum(df):\n",
    "    momentum_v = []\n",
    "    for x in range(0,len(df)):\n",
    "        E1 = df[\"shower1_E_Y\"].values[x]\n",
    "        E2 = df[\"shower2_E_Y\"].values[x]\n",
    "        x1 = df['shower1_dir_3d_X'].values[x]\n",
    "        y1 = df['shower1_dir_3d_Y'].values[x]\n",
    "        z1 = df['shower1_dir_3d_Z'].values[x]\n",
    "        x2 = df['shower2_dir_3d_X'].values[x]\n",
    "        y2 = df['shower2_dir_3d_Y'].values[x]\n",
    "        z2 = df['shower2_dir_3d_Z'].values[x]\n",
    "        #check magnitude\n",
    "        mag1 = sqrt(x1*x1+y1*y1+z1*z1)\n",
    "        mag2 = sqrt(x2*x2+y2*y2+z2*z2)\n",
    "        if E1<0 or E2<0 or mag1 <=0 or mag2 <=0:\n",
    "            momentum_v.append(-9999)\n",
    "        else:\n",
    "            singlevector1 = [(x1/mag1)*E1,(y1/mag1)*E1,(z1/mag1)*E1]\n",
    "            singlevector2 = [(x2/mag2)*E2,(y2/mag2)*E2,(z2/mag2)*E2]\n",
    "            momentumpi0 = [singlevector1[0]+singlevector2[0],singlevector1[1]+singlevector2[1],singlevector1[2]+singlevector2[2]]\n",
    "            momentum = sqrt(momentumpi0[0]**2+momentumpi0[1]**2+momentumpi0[2]**2)\n",
    "            momentum_v.append(momentum)\n",
    "    return momentum_v\n",
    "\n",
    "def recomomentum_v2(df):\n",
    "    momentum_v = []\n",
    "    for x in range(0,len(df)):\n",
    "        E1 = df[\"shower1_E_Y_new\"].values[x]\n",
    "        E2 = df[\"shower2_E_Y_new\"].values[x]\n",
    "        x1 = df['shower1_dir_3d_X'].values[x]\n",
    "        y1 = df['shower1_dir_3d_Y'].values[x]\n",
    "        z1 = df['shower1_dir_3d_Z'].values[x]\n",
    "        x2 = df['shower2_dir_3d_X'].values[x]\n",
    "        y2 = df['shower2_dir_3d_Y'].values[x]\n",
    "        z2 = df['shower2_dir_3d_Z'].values[x]\n",
    "        #check magnitude\n",
    "        mag1 = sqrt(x1*x1+y1*y1+z1*z1)\n",
    "        mag2 = sqrt(x2*x2+y2*y2+z2*z2)\n",
    "        if E1<0 or E2<0 or mag1 <=0 or mag2 <=0:\n",
    "            momentum_v.append(-9999)\n",
    "        else:\n",
    "            singlevector1 = [(x1/mag1)*E1,(y1/mag1)*E1,(z1/mag1)*E1]\n",
    "            singlevector2 = [(x2/mag2)*E2,(y2/mag2)*E2,(z2/mag2)*E2]\n",
    "            momentumpi0 = [singlevector1[0]+singlevector2[0],singlevector1[1]+singlevector2[1],singlevector1[2]+singlevector2[2]]\n",
    "            momentum = sqrt(momentumpi0[0]**2+momentumpi0[1]**2+momentumpi0[2]**2)\n",
    "            momentum_v.append(momentum)\n",
    "    return momentum_v\n",
    "\n",
    "\n",
    "def recopi0energy(df):\n",
    "    var = []\n",
    "    for x in range(len(df)):\n",
    "        m = df[\"_pi0mass\"].values[x]\n",
    "        E1 = df[\"shower1_E_Y\"].values[x]\n",
    "        E2 = df[\"shower2_E_Y\"].values[x]\n",
    "        theta = df['_shower_alpha'].values[x]\n",
    "        if (m<=0):\n",
    "            var.append(-9999)\n",
    "        else:\n",
    "            alpha = abs(E1-E2)/(E1+E2)\n",
    "            Energy = m*sqrt(2.0/((1-alpha**2)*(1-cos(theta))))\n",
    "            var.append(Energy)\n",
    "    return var\n",
    "\n",
    "def recopi0energy_v2(df):\n",
    "    var = []\n",
    "    for x in range(len(df)):\n",
    "        m = df[\"_pi0mass_new\"].values[x]\n",
    "        E1 = df[\"shower1_E_Y_new\"].values[x]\n",
    "        E2 = df[\"shower2_E_Y_new\"].values[x]\n",
    "        theta = df['_shower_alpha'].values[x]\n",
    "        if (m<=0):\n",
    "            var.append(-9999)\n",
    "        else:\n",
    "            alpha = abs(E1-E2)/(E1+E2)\n",
    "            Energy = m*sqrt(2.0/((1-alpha**2)*(1-cos(theta))))\n",
    "            var.append(Energy)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for df in df_list_mc:\n",
    "#     truemomemtum = truemomentum(df)\n",
    "#     trueenergy = truepi0energy(df)\n",
    "#     df['Pi0Energy_true'] = trueenergy\n",
    "#     df['Pi0Momenutum_true'] = truemomentum\n",
    "\n",
    "for df in df_list:\n",
    "    recom= recomomentum(df)\n",
    "    recoenergy = recopi0energy(df)\n",
    "    df['pi0_energy_reco'] = recoenergy\n",
    "    df['pi0_momentum_reco'] = recom\n",
    "    recom2= recomomentum_v2(df)\n",
    "    recoenergy2 = recopi0energy_v2(df)\n",
    "    df['pi0_energy_reco_new'] = recoenergy2\n",
    "    df['pi0_momentum_reco_new'] = recom2\n",
    "\n",
    "# trueE_bnb1,trueP_bnb1,truePx_bnb1,truePy_bnb1,truePz_bnb1 = truePi0(df_numu_goodruns_pmtprecut,truthdata_bnb_r1)\n",
    "# print(\"run1bnb done\")\n",
    "# trueE_bnb2,trueP_bnb2,truePx_bnb2,truePy_bnb2,truePz_bnb2 = truePi0(df_numu_r2_goodruns_pmtprecut,truthdata_bnb_r2)\n",
    "# print(\"run2bnb done\")\n",
    "# trueE_bnb3,trueP_bnb3,truePx_bnb3,truePy_bnb3,truePz_bnb3 = truePi0(df_numu_r3_goodruns_pmtprecut,truthdata_bnb_r3)\n",
    "# print(\"run3bnb done\")\n",
    "# trueE_nue1,trueP_nue1,truePx_nue1,truePy_nue1,truePz_nue1 = truePi0(df_nue_goodruns_pmtprecut,truthdata_nue_r1)\n",
    "# print(\"run1nue done\")\n",
    "# trueE_nue2,trueP_nue2,truePx_nue2,truePy_nue2,truePz_nue2 = truePi0(df_nue_r2_goodruns_pmtprecut,truthdata_nue_r2)\n",
    "# print(\"run2nue done\")\n",
    "# trueE_nue3,trueP_nue3,truePx_nue3,truePy_nue3,truePz_nue3 = truePi0(df_nue_r3_goodruns_pmtprecut,truthdata_nue_r3)\n",
    "# print(\"run3nue done\")\n",
    "\n",
    "# df_numu_goodruns_pmtprecut['pi0_energy_true'] = trueE_bnb1\n",
    "# df_numu_goodruns_pmtprecut['pi0_momentum_true']= trueP_bnb1\n",
    "# df_numu_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_bnb1\n",
    "# df_numu_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_bnb1\n",
    "# df_numu_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_bnb1\n",
    "# df_nue_goodruns_pmtprecut['pi0_energy_true'] = trueE_nue1\n",
    "# df_nue_goodruns_pmtprecut['pi0_momentum_true']= trueP_nue1\n",
    "# df_nue_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_nue1\n",
    "# df_nue_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_nue1\n",
    "# df_nue_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_nue1\n",
    "\n",
    "# df_numu_r2_goodruns_pmtprecut['pi0_energy_true'] = trueE_bnb2\n",
    "# df_numu_r2_goodruns_pmtprecut['pi0_momentum_true']= trueP_bnb2\n",
    "# df_numu_r2_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_bnb2\n",
    "# df_numu_r2_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_bnb2\n",
    "# df_numu_r2_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_bnb2\n",
    "# df_nue_r2_goodruns_pmtprecut['pi0_energy_true'] = trueE_nue2\n",
    "# df_nue_r2_goodruns_pmtprecut['pi0_momentum_true']= trueP_nue2\n",
    "# df_nue_r2_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_nue2\n",
    "# df_nue_r2_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_nue2\n",
    "# df_nue_r2_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_nue2\n",
    "\n",
    "# df_numu_r3_goodruns_pmtprecut['pi0_energy_true'] = trueE_bnb3\n",
    "# df_numu_r3_goodruns_pmtprecut['pi0_momentum_true']= trueP_bnb3\n",
    "# df_numu_r3_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_bnb3\n",
    "# df_numu_r3_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_bnb3\n",
    "# df_numu_r3_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_bnb3\n",
    "# df_nue_r3_goodruns_pmtprecut['pi0_energy_true'] = trueE_nue3\n",
    "# df_nue_r3_goodruns_pmtprecut['pi0_momentum_true']= trueP_nue3\n",
    "# df_nue_r3_goodruns_pmtprecut['pi0_momentum_x_true']= truePx_nue3\n",
    "# df_nue_r3_goodruns_pmtprecut['pi0_momentum_y_true']= truePy_nue3\n",
    "# df_nue_r3_goodruns_pmtprecut['pi0_momentum_z_true']= truePz_nue3\n",
    "\n",
    "# print(\"done with jsons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## angle resoultion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Angle_3d_1(df):\n",
    "    cos = []\n",
    "    for idx in range(len(df)):\n",
    "        if df['_pi0mass'].values[idx] >0 :\n",
    "            # calculate the cos 3d angle between two direction vectors\n",
    "            x1 = df['first_direction_true_X'].values[idx]\n",
    "            y1 = df['first_direction_true_Y'].values[idx]\n",
    "            z1 = df['first_direction_true_Z'].values[idx]\n",
    "            x2 = df['shower1_dir_3d_X'].values[idx]\n",
    "            y2 = df['shower1_dir_3d_Y'].values[idx]\n",
    "            z2 = df['shower1_dir_3d_Z'].values[idx]\n",
    "            mag1 = sqrt(x1*x1+y1*y1+z1*z1)*1.0\n",
    "            mag2 = sqrt(x2*x2+y2*y2+z2*z2)*1.0\n",
    "            dot = ((x1*x2)+(y1*y2)+(z1*z2))*1.0\n",
    "            cosangle = dot/(mag1*mag2)\n",
    "            cos.append(cosangle)\n",
    "        else:\n",
    "            cos.append(-9999)\n",
    "    return cos\n",
    "\n",
    "def Angle_3d_2(df):\n",
    "    cos = []\n",
    "    for idx in range(len(df)):\n",
    "        if df['_pi0mass'].values[idx] >0 :\n",
    "            # calculate the cos 3d angle between two direction vectors\n",
    "            x1 = df['second_direction_true_X'].values[idx]\n",
    "            y1 = df['second_direction_true_Y'].values[idx]\n",
    "            z1 = df['second_direction_true_Z'].values[idx]\n",
    "            x2 = df['shower2_dir_3d_X'].values[idx]\n",
    "            y2 = df['shower2_dir_3d_Y'].values[idx]\n",
    "            z2 = df['shower2_dir_3d_Z'].values[idx]\n",
    "            mag1 = sqrt(x1*x1+y1*y1+z1*z1)*1.0\n",
    "            mag2 = sqrt(x2*x2+y2*y2+z2*z2)*1.0\n",
    "            dot = ((x1*x2)+(y1*y2)+(z1*z2))*1.0\n",
    "            cosangle = dot/(mag1*mag2)\n",
    "            cos.append(cosangle)\n",
    "        else:\n",
    "            cos.append(-9999)\n",
    "    return cos\n",
    "\n",
    "\n",
    "for df in df_list_mc:\n",
    "    cos1 = Angle_3d_1(df)\n",
    "    cos2 = Angle_3d_2(df)\n",
    "    df['Pi0AngleRes_1'] = cos1\n",
    "    df['Pi0AngleRes_2'] = cos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Energy_1(df):\n",
    "    energy = []\n",
    "    for idx in range(len(df)):\n",
    "        if df['_pi0mass'].values[idx] >0 :\n",
    "            # calculate the cos 3d angle between two direction vectors\n",
    "            Er = df['shower1_E_Y_new'].values[idx]\n",
    "            Et = df['shower_energy_true'].values[idx]\n",
    "        \n",
    "            energy.append((Er-Et)/Et)\n",
    "        else:\n",
    "            energy.append(-9999)\n",
    "    return energy\n",
    "\n",
    "\n",
    "def Energy_2(df):\n",
    "    energy = []\n",
    "    for idx in range(len(df)):\n",
    "        if df['_pi0mass'].values[idx] >0 :\n",
    "            # calculate the cos 3d angle between two direction vectors\n",
    "            Er = df['shower2_E_Y_new'].values[idx]\n",
    "            Et = df['secondshower_energy_true'].values[idx]\n",
    "        \n",
    "            energy.append((Er-Et)/Et)\n",
    "        else:\n",
    "            energy.append(-9999)\n",
    "    return energy\n",
    "\n",
    "for df in df_list_mc:\n",
    "    e1 = Energy_1(df)\n",
    "    e2 = Energy_2(df)\n",
    "    df['Pi0EnergyRes_1'] = e1\n",
    "    df['Pi0EnergyRes_2'] = e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Econsit cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Econsist(df):\n",
    "    const = []\n",
    "    for i in range(len(df)):\n",
    "        EU = df['shower1_sumQ_U'].values[i]*0.0139 + 31.5\n",
    "        EV = df['shower1_sumQ_V'].values[i]*0.0143 + 35.7\n",
    "        EY = df['shower1_sumQ_Y'].values[i]*0.0125 + 13.8       \n",
    "        const.append(sqrt((EU-EV)**2 + (EU-EY)**2 + (EY-EV)**2)/EY)\n",
    "    return const\n",
    "\n",
    "for df in df_list:\n",
    "    const = Econsist(df)\n",
    "    df['Econsit'] = const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write df back to pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numu_goodruns_pmtprecut.to_pickle(pickle_numu_goodruns_pmtprecut)\n",
    "df_nue_goodruns_pmtprecut.to_pickle(pickle_nue_goodruns_pmtprecut)\n",
    "df_ext_goodruns_pmtprecut.to_pickle(pickle_ext_goodruns_pmtprecut)\n",
    "\n",
    "df_numu_r3_goodruns_pmtprecut.to_pickle(pickle_numu_r3_goodruns_pmtprecut)\n",
    "df_nue_r3_goodruns_pmtprecut.to_pickle(pickle_nue_r3_goodruns_pmtprecut)\n",
    "df_ext_r3_goodruns_pmtprecut.to_pickle(pickle_ext_r3_goodruns_pmtprecut)\n",
    "\n",
    "df_numu_r2_goodruns_pmtprecut.to_pickle(pickle_numu_r2_goodruns_pmtprecut)\n",
    "df_nue_r2_goodruns_pmtprecut.to_pickle(pickle_nue_r2_goodruns_pmtprecut)\n",
    "\n",
    "df_data_r1_pi0filter_pmtprecut.to_pickle(pickle_data_r1_pi0filter_pmtprecut)\n",
    "df_data_r2d_pi0filter_pmtprecut.to_pickle(pickle_data_r2d_pi0filter_pmtprecut)\n",
    "df_data_r2e_pi0filter_pmtprecut.to_pickle(pickle_data_r2e_pi0filter_pmtprecut)\n",
    "df_data_r3f_pi0filter_pmtprecut.to_pickle(pickle_data_r3f_pi0filter_pmtprecut)\n",
    "df_data_r3g_pi0filter_pmtprecut.to_pickle(pickle_data_r3g_pi0filter_pmtprecut)\n",
    "# df_data_r3_open_pmtprecut.to_pickle(pickle_data_r3_open_pmtprecut)\n",
    "df_data_goodruns_pmtprecut.to_pickle(pickle_data_goodruns_pmtprecut)\n",
    "\n",
    "# df_fakedata1_goodruns_run1_pmtprecut.to_pickle(pickle_fakedata1_goodruns_run1_pmtprecut)\n",
    "# df_fakedata1_goodruns_run3_pmtprecut.to_pickle(pickle_fakedata1_goodruns_run3_pmtprecut)\n",
    "# df_fakedata2_goodruns_run1_pmtprecut.to_pickle(pickle_fakedata2_goodruns_run1_pmtprecut)\n",
    "# df_fakedata2_goodruns_run3_pmtprecut.to_pickle(pickle_fakedata2_goodruns_run3_pmtprecut)\n",
    "# df_fakedata3_goodruns_run1_pmtprecut.to_pickle(pickle_fakedata3_goodruns_run1_pmtprecut)\n",
    "# df_fakedata3_goodruns_run3_pmtprecut.to_pickle(pickle_fakedata3_goodruns_run3_pmtprecut)\n",
    "# df_fakedata4_goodruns_run1_pmtprecut.to_pickle(pickle_fakedata4_goodruns_run1_pmtprecut)\n",
    "# df_fakedata4_goodruns_run3_pmtprecut.to_pickle(pickle_fakedata4_goodruns_run3_pmtprecut)\n",
    "# df_fakedata5_goodruns_run1_pmtprecut.to_pickle(pickle_fakedata5_goodruns_run1_pmtprecut)\n",
    "# print(df_fakedata5_goodruns_run1_pmtprecut['pi0_energy_reco'].values)\n",
    "# numu_wmodX_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_overlay_wiremodX.pkl\")\n",
    "# numu_wmodYZ_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodYZ.pkl\")\n",
    "# numu_thetaXZ_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodThetaXZ.pkl\")\n",
    "# numu_thetaYZ_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodThetaYZ.pkl\")\n",
    "# numu_dedx_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodscaleddedx.pkl\") \n",
    "# numu_SCE_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_SCE.pkl\")\n",
    "# numu_LYdown_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_LYdown.pkl\")\n",
    "# numu_LYR_df.to_pickle(\"/media/disk1/kmason/mcc9_v40_dl_run3b_bnb_nu_overlay_DetVar_LYRayleigh.pkl\")\n",
    "# numu_LYAtt_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_LYAttenuation.pkl\")\n",
    "# numu_recomb_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_recomb2.pkl\")\n",
    "# numu_CV_df.to_pickle(\"/media/disk1/kmason/mcc9_v40a_dl_run3b_bnb_overlay_CV.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
