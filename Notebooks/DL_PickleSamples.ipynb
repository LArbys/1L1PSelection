{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/04\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from numpy import mean\n",
    "from math import sqrt,acos,cos,sin,pi,exp,log,isnan,atan2\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import asarray\n",
    "from root_pandas import read_root\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "\n",
    "datafolder = '../../data'\n",
    "dumpfolder = '../PlotDumps'\n",
    "RSE  = ['run','subrun','event']\n",
    "RSEV = ['run','subrun','event','vtxid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes all of the cumbersome input files necessary for this analysis and creates neat, portable parquet files containing the dataframes which can be easily used throughout the rest of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load BDT weights from pickles. These BDTs are already applied in the DLAna processing stage, but I have this implemented for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/dcianci/Physics/1e1p/testzone/1L1PSelection/bdt_models/bdtweight_series2_june1_run1.pickle','rb') as handle: bkgBDT_run1 = pickle.load(handle)          # Load BDT weights for 1mu1p background differentiation     \n",
    "with open('/home/dcianci/Physics/1e1p/testzone/1L1PSelection/bdt_models/bdtweight_series2_june1_run3.pickle','rb') as handle: bkgBDT_run3 = pickle.load(handle)          # Load BDT weights for 1mu1p background differentiation  \n",
    "    \n",
    "# the variables used as BDT features\n",
    "vars_june1 = ['Phis','ChargeNearTrunk','Enu_1m1p','PhiT_1m1p','AlphaT_1m1p','PT_1m1p','PTRat_1m1p','BjXB_1m1p','BjYB_1m1p','SphB_1m1p','Q0_1m1p','Q3_1m1p','Lepton_PhiReco','Lepton_TrackLength','Proton_PhiReco','Proton_ThetaReco']\n",
    "bdtVars = vars_june1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb.dump(bkgBDT_run1,'bkgBDT_run1')\n",
    "type(bkgBDT_run1)\n",
    "bkgBDT_run1.save_model('bkgBDT_run1.model')\n",
    "bkgBDT_run3.save_model('bkgBDT_run3.model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My homebrew MC labeling scheme for easy sorting and plotting later on: In bless_int_labels, elements of a dataframe are assigned labels based on underlying neutrino interaction; in bless_MC_labels, we do the same thing, but add additional reconstruction qualifiers as described in the DL internal note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bless_MC_labels(row):\n",
    "    mclabel = ''\n",
    "    intlabel = ''\n",
    "    parentlabel = ''\n",
    "    pizero = [1090,1086,1090,1080,1015,1013,1011,1008,1006,1004]\n",
    "    piplusminus = [1085,1079,1032,1017,1014,1007,1005,1003,1028,1021,1016,1012,1010,1009]\n",
    "        \n",
    "    if abs(row['nu_pdg']) == 12:\n",
    "        intlabel = 'nue'\n",
    "    elif abs(row['nu_pdg']) == 14:\n",
    "        intlabel = 'numu'\n",
    "        \n",
    "    if not (row['MC_nproton']==1 and row['MC_nlepton']==1):\n",
    "        return 'nLmP'\n",
    "    elif not 0 < row['MC_scedr'] <= 5.0:\n",
    "        return 'offvtx'\n",
    "    elif not abs((row['MC_energyInit']-row['Enu_1m1p'])/row['MC_energyInit']) < 0.2:\n",
    "        return 'badreco'    \n",
    "    else:\n",
    "        if row['nu_interaction_type'] == 1001:\n",
    "            mclabel = 'CCQE'\n",
    "        elif row['nu_interaction_type'] == 1000:\n",
    "            mclabel = 'MEC'\n",
    "        elif row['nu_interaction_type'] in pizero:\n",
    "            mclabel = 'pizero'\n",
    "        elif row['nu_interaction_type'] in piplusminus:\n",
    "            mclabel = 'piplusminus' \n",
    "        else:\n",
    "            mclabel = 'other'\n",
    "    return '%s_%s'%(intlabel,mclabel)\n",
    "\n",
    "def bless_int_labels(row):\n",
    "    mclabel = ''\n",
    "    intlabel = ''\n",
    "    parentlabel = ''\n",
    "    pizero = [1090,1086,1090,1080,1015,1013,1011,1008,1006,1004]\n",
    "    piplusminus = [1085,1079,1032,1017,1014,1007,1005,1003,1028,1021,1016,1012,1010,1009]\n",
    "        \n",
    "    if abs(row['nu_pdg']) == 12:\n",
    "        intlabel = 'nue'\n",
    "    elif abs(row['nu_pdg']) == 14:\n",
    "        intlabel = 'numu'\n",
    "        \n",
    "    if row['nu_interaction_type'] == 1001:\n",
    "        mclabel = 'CCQE'\n",
    "    elif row['nu_interaction_type'] == 1000:\n",
    "        mclabel = 'MEC'\n",
    "    elif row['nu_interaction_type'] in pizero:\n",
    "        mclabel = 'pizero'\n",
    "    elif row['nu_interaction_type'] in piplusminus:\n",
    "        mclabel = 'piplusminus' \n",
    "    else:\n",
    "        mclabel = 'other'\n",
    "           \n",
    "    return '%s_%s'%(intlabel,mclabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a tag for the parquets to be exported here and now. Some space is provided describing previous tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = 'Feb16_ForOsc'\n",
    "\n",
    "# Tag dictionary:\n",
    "# Oct21_cmt - all up to date as of the collaboration meeting in october. Identical selection to internal note, now with training samples marked\n",
    "# RunCompatibility - tune 1 and special BDT training for tests\n",
    "# Nov17_tune2 - Same as Oct21_cmt, but now all runs have genie tune 2 weighting\n",
    "# Feb10_pi0wgt - Same as Nov17_tune2, but with pi0 weights\n",
    "\n",
    "# All Precuts\n",
    "orthogonalcut = 'MaxShrFrac < .2'\n",
    "precuts ='PassSimpleCuts == 1 and ChargeNearTrunk > 0 and FailedBoost != 1 and OpenAng > .5'\n",
    "pmtprecuts = 'TotPE > 20 and PorchTotPE < 20'\n",
    "s_precut = orthogonalcut + ' and ' + precuts + ' and ' + pmtprecuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to \"process\" the MC. Given the MC dataframe, the weights dataframe, the good runs dataframe and the BDT weights to be used, we combine everything neatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_df(df_dlana,df_wgts,df_goodrun,bdtwgts,isMC=True):\n",
    "    \n",
    "    # join with goodruns list and cv weights list\n",
    "    df_full = df_dlana.join(df_goodrun.set_index('run'),on='run')\n",
    "    if(isMC):\n",
    "        df_full = df_full.join(df_wgts.set_index(RSE)[['nu_interaction_mode','nu_interaction_type','xsec_corr_weight','spline_weight','nu_interaction_ccnc','nu_pdg','nu_energy_true','nu_L_true']],on=RSE)\n",
    "    df_full_goodruns = df_full.query('good==1')   # keep good runs\n",
    "    df_full_goodruns_precuts = df_full_goodruns.query(s_precut)    # apply precuts\n",
    "       \n",
    "    if(isMC):\n",
    "        df_full_goodruns_precuts.insert(0,'mc_label',df_full_goodruns_precuts.apply(bless_MC_labels,axis=1))\n",
    "        df_full_goodruns_precuts.insert(0,'int_label',df_full_goodruns_precuts.apply(bless_int_labels,axis=1))\n",
    "       \n",
    "    # add a bunch of helpful variables!\n",
    "    df_full_goodruns_precuts.insert(0,'MPID_eminus',[ef.max() for ef in df_full_goodruns_precuts['EminusPID_int_v'].values])\n",
    "    df_full_goodruns_precuts.insert(0,'MPID_muon',[ef.max() for ef in df_full_goodruns_precuts['MuonPID_int_v'].values])\n",
    "    df_full_goodruns_precuts.insert(0,'MPID_proton',[ef.max() for ef in df_full_goodruns_precuts['ProtonPID_int_v'].values])\n",
    "    df_full_goodruns_precuts.insert(0,'MPID_gamma',[ef.max() for ef in df_full_goodruns_precuts['GammaPID_int_v'].values])\n",
    "    df_full_goodruns_precuts.insert(0,'MPID_pion',[ef.max() for ef in df_full_goodruns_precuts['PionPID_int_v'].values])\n",
    "    df_full_goodruns_precuts.insert(0,'Lepton_CosTheta',np.cos(df_full_goodruns_precuts['Lepton_ThetaReco'].values).tolist())\n",
    "    df_full_goodruns_precuts.insert(0,'Proton_CosTheta',np.cos(df_full_goodruns_precuts['Proton_ThetaReco'].values).tolist())\n",
    "    \n",
    "    # add most current bdt weights.\n",
    "    # bdt weights are applied as  bkgBDT_univ[ersal] so whether we are dealing with Run 1, 2 or 3, we are calling the correct weight, rather than one for a particular Run.\n",
    "    df_full_goodruns_precuts.insert(0,'bkgBDT_univ',bdtwgts.predict_proba(df_full_goodruns_precuts[bdtVars].values.tolist())[:,0])\n",
    "    # for each event, keep only vertex with best (most signal-like) BDT score\n",
    "    df_full_nodupes = df_full_goodruns_precuts.sort_values('bkgBDT_univ',ascending=True).drop_duplicates(RSE).sort_index()\n",
    "    return df_full_nodupes\n",
    "    \n",
    "def proc_df_fakedata(df_dlana,bdtwgts):\n",
    "    \n",
    "    df_full_precuts = df_dlana.query(s_precut)    # apply precuts\n",
    "    \n",
    "    # add a bunch of helpful variables!\n",
    "    df_full_precuts.insert(0,'MPID_eminus',[ef.max() for ef in df_full_precuts['EminusPID_int_v'].values])\n",
    "    df_full_precuts.insert(0,'MPID_muon',[ef.max() for ef in df_full_precuts['MuonPID_int_v'].values])\n",
    "    df_full_precuts.insert(0,'MPID_proton',[ef.max() for ef in df_full_precuts['ProtonPID_int_v'].values])\n",
    "    df_full_precuts.insert(0,'MPID_gamma',[ef.max() for ef in df_full_precuts['GammaPID_int_v'].values])\n",
    "    df_full_precuts.insert(0,'MPID_pion',[ef.max() for ef in df_full_precuts['PionPID_int_v'].values])\n",
    "    df_full_precuts.insert(0,'Lepton_CosTheta',np.cos(df_full_precuts['Lepton_ThetaReco'].values).tolist())\n",
    "    df_full_precuts.insert(0,'Proton_CosTheta',np.cos(df_full_precuts['Proton_ThetaReco'].values).tolist())\n",
    "    \n",
    "    # add most current bdt weights.\n",
    "    df_full_precuts.insert(0,'bkgBDT_univ',bdtwgts.predict_proba(df_full_precuts[bdtVars].values.tolist())[:,0])\n",
    "    df_full_nodupes = df_full_precuts.sort_values('bkgBDT_univ',ascending=True).drop_duplicates(RSE).sort_index()\n",
    "    \n",
    "    return df_full_nodupes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the good runs lists into simple dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_run1_df = pd.read_csv('%s/goodruns_2020.txt'%datafolder)\n",
    "good_run2_df = pd.read_csv('%s/goodruns_2020_run2.txt'%datafolder)\n",
    "good_run3_df = pd.read_csv('%s/goodruns_2020_run3.txt'%datafolder)\n",
    "\n",
    "good_run1_df['good'] = 1\n",
    "good_run2_df['good'] = 1\n",
    "good_run3_df['good'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary to label whether or not a given event is in the BDT training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are we in  the training sample?\n",
    "a_train_run1 = np.genfromtxt('bdt_run1_trainsample.csv',delimiter=',')\n",
    "a_train_run3 = np.genfromtxt('bdt_run3_trainsample.csv',delimiter=',')\n",
    "dic_train = {}\n",
    "\n",
    "for tr in a_train_run1:\n",
    "    idx = tuple((tr[0],tr[1]))\n",
    "    dic_train[idx] = dict(intrain=1)\n",
    "\n",
    "for tr in a_train_run3:\n",
    "    idx = tuple((tr[0],tr[1]))\n",
    "    dic_train[idx] = dict(intrain=1)\n",
    "    \n",
    "def InTrainRun(row):\n",
    "    try:\n",
    "        return dic_train[row.run,row.subrun]['intrain']\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam quality\n",
    "beamq_df = read_root('%s/beamdataquality_remix_bnb5e19.root'%datafolder,'bdq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC BNB OVERLAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mc = 'numu_run1'\n",
    "df_mc = read_root('%s/bnb_overlay/mcc9_v28_wctagger_bnboverlay_stripped.root'%datafolder,'FinalVertexVariables')\n",
    "df_mc_cvweight = read_root('%s/bnb_overlay/weights_forCV_v48_Sep24_bnb_nu_run1.root'%datafolder) #tune 2\n",
    "#df_mc_cvweight = read_root('%s/bnb_overlay/arxiv/weights_forCV_v40_bnb_nu_run1.root'%datafolder) # tune 1\n",
    "\n",
    "df_mc_pi0wgt = pd.read_csv('%s/pi0weight/Dec14_pi0_weights_numu_run1_forDavio.txt'%datafolder)\n",
    "df_mc = df_mc.join(df_mc_pi0wgt.set_index(RSE),on=RSE)\n",
    "\n",
    "df_mc.insert(0,'InTraining',df_mc.apply(InTrainRun,axis=1))\n",
    "\n",
    "df_mc_full = proc_df(df_mc,df_mc_cvweight,good_run1_df,bkgBDT_run1,True) \n",
    "df_mc_full = df_mc_full.query('not (nu_interaction_ccnc==0 and abs(nu_pdg)==12)') # cut out nue ccqes (to avoid overcounting with nue intrinsics)\n",
    "\n",
    "df_mc_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_mc,tag))\n",
    "\n",
    "del df_mc, df_mc_cvweight, df_mc_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mc = 'numu_run1'\n",
    "df_mc = read_root('%s/bnb_overlay/mcc9_v28_wctagger_bnboverlay_stripped.root'%datafolder,'FinalVertexVariables')\n",
    "\n",
    "df_mc_pi0wgt = pd.read_csv('%s/pi0weight/Dec14_pi0_weights_numu_run1_forDavio.txt'%datafolder)\n",
    "df_mc = df_mc.join(df_mc_pi0wgt.set_index(RSE),on=RSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3091200927085052\n"
     ]
    }
   ],
   "source": [
    "print(np.nan_to_num(df_mc['pi0 weight'].values).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mc = 'numu_lowe_run1'\n",
    "df_mc = read_root('%s/bnb_overlay/mcc9_v29e_run1_bnb_nu_overlay_LowE.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "df_mc_cvweight = read_root('%s/bnb_overlay/weights_forCV_v48_Sep24_bnb_nu_lowE_run1.root'%datafolder)\n",
    "\n",
    "df_mc.insert(0,'InTraining',df_mc.apply(InTrainRun,axis=1))\n",
    "\n",
    "df_mc_full = proc_df(df_mc,df_mc_cvweight,good_run1_df,bkgBDT_run1,True)\n",
    "df_mc_full = df_mc_full.query('not (nu_interaction_ccnc==0 and abs(nu_pdg)==12)') # cut out nue ccqes\n",
    "\n",
    "df_mc_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_mc,tag))\n",
    "\n",
    "del df_mc, df_mc_cvweight, df_mc_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run 2\n",
    "Run 2 had some small indexing errors that I needed to resolve manually (ie: multiple events had the same RSE  and therefore needed new indices. Very annoying.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_mc = 'numu_run2'\n",
    "df_mc = read_root('%s/bnb_overlay/mcc9_v29e_dl_run2_bnb_nu_overlay_finalbdt.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "df_mc_cvweight = read_root('%s/bnb_overlay/weights_forCV_v48_Sep24_bnb_nu_run2.root'%datafolder)\n",
    "\n",
    "df_mc_pi0wgt = pd.read_csv('%s/pi0weight/Dec14_pi0_weights_numu_run2_forDavio.txt'%datafolder)\n",
    "df_mc = df_mc.join(df_mc_pi0wgt.set_index(RSE),on=RSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bless_cvindex(row):\n",
    "    df_subsec = df_mc_cvweight.query('run==%s and subrun==%s and event==%s'%(row['run'],row['subrun'],row['event']))   \n",
    "    if(len(df_subsec) == 0):\n",
    "        return np.nan\n",
    "    if(len(df_subsec) == 1):\n",
    "        return df_subsec.index[0]\n",
    "    idx = np.argmin(np.abs(df_subsec['nu_energy_true'].values-row['MC_energyInit']))\n",
    "    return df_subsec.index[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_mc.join(good_run2_df.set_index('run'),on='run')\n",
    "df_full_goodruns = df_full.query('good==1')   # keep good runs\n",
    "df_full_goodruns_precuts = df_full_goodruns.query(s_precut)    # apply precuts\n",
    "    \n",
    "df_full_goodruns_precuts.insert(0,'CVIndex',df_full_goodruns_precuts.apply(bless_cvindex,axis=1)) # this takes forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a bunch of helpful variables!\n",
    "df_full_goodruns_precuts.insert(0,'MPID_eminus',[ef.max() for ef in df_full_goodruns_precuts['EminusPID_int_v'].values])\n",
    "df_full_goodruns_precuts.insert(0,'MPID_muon',[ef.max() for ef in df_full_goodruns_precuts['MuonPID_int_v'].values])\n",
    "df_full_goodruns_precuts.insert(0,'MPID_proton',[ef.max() for ef in df_full_goodruns_precuts['ProtonPID_int_v'].values])\n",
    "df_full_goodruns_precuts.insert(0,'MPID_gamma',[ef.max() for ef in df_full_goodruns_precuts['GammaPID_int_v'].values])\n",
    "df_full_goodruns_precuts.insert(0,'MPID_pion',[ef.max() for ef in df_full_goodruns_precuts['PionPID_int_v'].values])\n",
    "df_full_goodruns_precuts.insert(0,'Lepton_CosTheta',np.cos(df_full_goodruns_precuts['Lepton_ThetaReco'].values).tolist())\n",
    "df_full_goodruns_precuts.insert(0,'Proton_CosTheta',np.cos(df_full_goodruns_precuts['Proton_ThetaReco'].values).tolist())\n",
    "    \n",
    "# add most current bdt weights.\n",
    "df_full_goodruns_precuts.insert(0,'bkgBDT_univ',bkgBDT_run3.predict_proba(df_full_goodruns_precuts[bdtVars].values.tolist())[:,0])\n",
    "df_full_nodupes = df_full_goodruns_precuts.sort_values('bkgBDT_univ',ascending=True).drop_duplicates('CVIndex').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_cved = df_full_nodupes.join(df_mc_cvweight[['nu_interaction_mode','nu_interaction_type','xsec_corr_weight','spline_weight','nu_interaction_ccnc','nu_pdg','nu_energy_true','nu_L_true']],on='CVIndex')\n",
    "df_full_cved.insert(0,'mc_label',df_full_cved.apply(bless_MC_labels,axis=1))\n",
    "df_full_cved.insert(0,'int_label',df_full_cved.apply(bless_int_labels,axis=1))\n",
    "     \n",
    "df_mc_final = df_full_cved.query('not (nu_interaction_ccnc==0 and abs(nu_pdg)==12)') # cut out nue ccqes\n",
    "df_mc_final.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_mc,tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mc = 'numu_run3'\n",
    "df_mc = read_root('%s/bnb_overlay/mcc9_v29e_dl_run3b_bnb_nu_overlay_nocrtremerge_stripped.root'%datafolder,'FinalVertexVariables')\n",
    "#df_mc_cvweight = read_root('%s/bnb_overlay/weights_forCV_v48_Sep24_bnb_nu_run3.root'%datafolder) # tune 2\n",
    "df_mc_cvweight = read_root('%s/bnb_overlay/arxiv/weights_forCV_v40_bnb_nu_run3.root'%datafolder) #tune 1\n",
    "\n",
    "df_mc_pi0wgt = pd.read_csv('%s/pi0weight/Dec14_pi0_weights_numu_run3_forDavio.txt'%datafolder)\n",
    "df_mc = df_mc.join(df_mc_pi0wgt.set_index(RSE),on=RSE)\n",
    "\n",
    "df_mc.insert(0,'InTraining',df_mc.apply(InTrainRun,axis=1))\n",
    "\n",
    "df_mc_full = proc_df(df_mc,df_mc_cvweight,good_run3_df,bkgBDT_run3,True) \n",
    "df_mc_full.to_parquet('mcc9_v29e_dl_run3b_bnb_nu_overlay_nocrtremerge_stripped_wBDT.parquet')\n",
    "\n",
    "df_mc_full = df_mc_full.query('not (nu_interaction_ccnc==0 and abs(nu_pdg)==12)') # cut out nue ccqes\n",
    "\n",
    "#df_mc_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_mc,tag))\n",
    "\n",
    "#del df_mc, df_mc_cvweight, df_mc_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mc = 'numu_run3'\n",
    "df_mc = read_root('%s/bnb_overlay/mcc9_v29e_dl_run3b_bnb_nu_overlay_nocrtremerge_stripped.root'%datafolder,'FinalVertexVariables')\n",
    "#df_mc_cvweight = read_root('%s/bnb_overlay/weights_forCV_v48_Sep24_bnb_nu_run3.root'%datafolder) # tune 2\n",
    "df_mc_cvweight = read_root('%s/bnb_overlay/arxiv/weights_forCV_v40_bnb_nu_run3.root'%datafolder) #tune 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mc_pi0wgt = pd.read_csv('%s/pi0weight/Dec14_pi0_weights_numu_run3_forDavio.txt'%datafolder)\n",
    "df_mc = df_mc.join(df_mc_pi0wgt.set_index(RSE),on=RSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mc.insert(0,'InTraining',df_mc.apply(InTrainRun,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mc_full = proc_df(df_mc,df_mc_cvweight,good_run3_df,bkgBDT_run3,True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1405    12\n",
       "Name: nu_pdg, dtype: int32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mc_full.query('run==16949 and subrun==252 and event==12625')['nu_pdg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC NUE OVERLAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mc = 'nue_run1'\n",
    "df_mc = read_root('%s/nue_intrinsic_overlay/mcc9_v28_wctagger_nueintrinsics_stripped.root'%datafolder,'FinalVertexVariables')\n",
    "#df_mc_cvweight = read_root('%s/nue_intrinsic_overlay/weights_forCV_v48_Sep24_intrinsic_nue_run1.root'%datafolder) #tune 2\n",
    "df_mc_cvweight = read_root('%s/nue_intrinsic_overlay/arxiv/weights_forCV_v40_intrinsic_nue_run1.root'%datafolder) # tune 1\n",
    "\n",
    "df_mc_pi0wgt = pd.read_csv('%s/pi0weight/Dec14_pi0_weights_nue_run1_forDavio.txt'%datafolder)\n",
    "df_mc = df_mc.join(df_mc_pi0wgt.set_index(RSE),on=RSE)\n",
    "\n",
    "df_mc.insert(0,'InTraining',df_mc.apply(InTrainRun,axis=1))\n",
    "\n",
    "df_mc_full = proc_df(df_mc,df_mc_cvweight,good_run1_df,bkgBDT_run1,True)\n",
    "\n",
    "df_mc_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_mc,tag))\n",
    "\n",
    "del df_mc, df_mc_cvweight, df_mc_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mc = 'nue_run2'\n",
    "df_mc = read_root('%s/nue_intrinsic_overlay/mcc9_v29e_dl_run2_bnb_intrinsics_nue_overlay_finalbdt.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "df_mc_cvweight = read_root('%s/nue_intrinsic_overlay/weights_forCV_v48_Sep24_intrinsic_nue_run2.root'%datafolder)\n",
    "\n",
    "df_mc_pi0wgt = pd.read_csv('%s/pi0weight/Dec14_pi0_weights_nue_run2_forDavio.txt'%datafolder)\n",
    "df_mc = df_mc.join(df_mc_pi0wgt.set_index(RSE),on=RSE)\n",
    "\n",
    "df_mc_full = proc_df(df_mc,df_mc_cvweight,good_run2_df,bkgBDT_run3,True)\n",
    "\n",
    "df_mc_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_mc,tag))\n",
    "\n",
    "del df_mc, df_mc_cvweight, df_mc_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mc = 'nue_run3'\n",
    "df_mc = read_root('%s/nue_intrinsic_overlay/mcc9_v29e_run3b_bnb_intrinsic_nue_overlay_nocrtremerge_stripped.root'%datafolder,'FinalVertexVariables')\n",
    "#df_mc_cvweight = read_root('%s/nue_intrinsic_overlay/weights_forCV_v48_Sep24_intrinsic_nue_run3.root'%datafolder)  # tune 2\n",
    "df_mc_cvweight = read_root('%s/nue_intrinsic_overlay/arxiv/weights_forCV_v40_intrinsic_nue_run3.root'%datafolder) # tune 1\n",
    "\n",
    "df_mc_pi0wgt = pd.read_csv('%s/pi0weight/Dec14_pi0_weights_nue_run3_forDavio.txt'%datafolder)\n",
    "df_mc = df_mc.join(df_mc_pi0wgt.set_index(RSE),on=RSE)\n",
    "\n",
    "df_mc.insert(0,'InTraining',df_mc.apply(InTrainRun,axis=1))\n",
    "\n",
    "df_mc_full = proc_df(df_mc,df_mc_cvweight,good_run3_df,bkgBDT_run3,True)\n",
    "\n",
    "df_mc_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_mc,tag))\n",
    "\n",
    "del df_mc, df_mc_cvweight, df_mc_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>subrun</th>\n",
       "      <th>event</th>\n",
       "      <th>pi0weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17753</td>\n",
       "      <td>166</td>\n",
       "      <td>8308</td>\n",
       "      <td>0.963621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14877</td>\n",
       "      <td>177</td>\n",
       "      <td>8874</td>\n",
       "      <td>0.836396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16446</td>\n",
       "      <td>183</td>\n",
       "      <td>9179</td>\n",
       "      <td>0.687725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15492</td>\n",
       "      <td>90</td>\n",
       "      <td>4549</td>\n",
       "      <td>0.698774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15785</td>\n",
       "      <td>162</td>\n",
       "      <td>8120</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17662</td>\n",
       "      <td>97</td>\n",
       "      <td>4855</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14455</td>\n",
       "      <td>142</td>\n",
       "      <td>7108</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16159</td>\n",
       "      <td>8</td>\n",
       "      <td>430</td>\n",
       "      <td>0.729623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15106</td>\n",
       "      <td>190</td>\n",
       "      <td>9537</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15935</td>\n",
       "      <td>146</td>\n",
       "      <td>7332</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14343</td>\n",
       "      <td>302</td>\n",
       "      <td>15143</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13965</td>\n",
       "      <td>44</td>\n",
       "      <td>2204</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      run  subrun  event  pi0weight\n",
       "0   17753     166   8308   0.963621\n",
       "1   14877     177   8874   0.836396\n",
       "2   16446     183   9179   0.687725\n",
       "3   15492      90   4549   0.698774\n",
       "4   15785     162   8120   1.000000\n",
       "5   17662      97   4855   1.000000\n",
       "6   14455     142   7108   1.000000\n",
       "7   16159       8    430   0.729623\n",
       "8   15106     190   9537   1.000000\n",
       "9   15935     146   7332   1.000000\n",
       "10  14343     302  15143   1.000000\n",
       "11  13965      44   2204   1.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mc_pi0wgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_mc = 'dirt_run1'\n",
    "# df_mc = read_root('%s/dirt/FVV-Prime-dirt-Mar3-WC-1M1P.root'%datafolder,'FinalVertexVariables')\n",
    "# df_mc_cvweight = read_root('%s/dirt/weights_forCV_v40_dirt_nu_run1.root'%datafolder)\n",
    "\n",
    "# df_mc_full = proc_df(df_mc,df_mc_cvweight,good_run1_df,bkgBDT_run1,True)\n",
    "\n",
    "# df_mc_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_mc,tag))\n",
    "\n",
    "# del df_mc, df_mc_cvweight, df_mc_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ext = 'ext_run1'\n",
    "df_ext = read_root('%s/ext/mcc9_v28_wctagger_extbnbFULL_stripped.root'%datafolder)\n",
    "\n",
    "df_ext.insert(0,'InTraining',df_ext.apply(InTrainRun,axis=1))\n",
    "\n",
    "df_ext_full = proc_df(df_ext,'',good_run1_df,bkgBDT_run1,False)\n",
    "\n",
    "df_ext_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_ext,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ext = 'ext_run3'\n",
    "df_ext = read_root('%s/ext/mcc9_v29e_dl_run3_G1_extbnb_stripped.root'%datafolder)\n",
    "    \n",
    "df_ext.insert(0,'InTraining',df_ext.apply(InTrainRun,axis=1))\n",
    "\n",
    "df_ext_full = proc_df(df_ext,'',good_run3_df,bkgBDT_run3,False)\n",
    "\n",
    "df_ext_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_ext,tag)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'data_run1_5e19_beamqualitytag'\n",
    "df_data = read_root('%s/bnb/mcc9_v28_wctagger_5e19.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "# add beam quality filter\n",
    "df_data = df_data.join(beamq_df.set_index(['run','subrun','event']),on=['run','subrun','event'])\n",
    "df_data_full = proc_df(df_data,'',good_run1_df,bkgBDT_run1,False)\n",
    "\n",
    "df_data_full['InTraining'] = 0\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'data_run3_1e19'\n",
    "df_data = read_root('%s/bnb/mcc9_v28_wctagger_run3_bnb1e19.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "df_data_full = proc_df(df_data,'',good_run3_df,bkgBDT_run3,False)\n",
    "\n",
    "df_data_full['InTraining'] = 0\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'data_run2_filter'\n",
    "df_data = read_root('%s/bnb/mcc9_v29e_run2_D2E1_1m1p_fvv.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "df_data_full = proc_df(df_data,'',good_run2_df,bkgBDT_run2,False)\n",
    "\n",
    "df_data_full['InTraining'] = 0\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'data_run3_filter'\n",
    "df_data = read_root('%s/bnb/mcc9_v29e_run3_F1G1_1m1p_fvv.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "df_data_full = proc_df(df_data,'',good_run3_df,bkgBDT_run3,False)\n",
    "\n",
    "df_data_full['InTraining'] = 0\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'data_run1_filter'\n",
    "df_data = read_root('%s/bnb/mcc9_v29e_dl_run1_C1_bnb_dlfilter_1m1p_v1_1_2b_fvv.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "df_data_full = proc_df(df_data,'',good_run1_df,bkgBDT_run1,False)\n",
    "\n",
    "df_data_full['InTraining'] = 0\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'fakedata_set1_run1'\n",
    "df_data = read_root('%s/fakedata/dlfilter_fakedata_v08_00_00_29e_dl_ubdlana_v1_1_2_set1_run1_1m1p_stripped.root'%datafolder,'FinalVertexVariables')\n",
    "\n",
    "# remember to turn off pmt precuts\n",
    "df_data_full = proc_df_fakedata(df_data,bkgBDT_run1)\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'fakedata_set1_run3b'\n",
    "df_data = read_root('%s/fakedata/dlfilter_fakedata_v08_00_00_29e_dl_ubdlana_v1_1_2_set1_run3b_1m1p_stripped.root'%datafolder,'FinalVertexVariables')\n",
    "\n",
    "# remember to turn off pmt precuts\n",
    "df_data_full = proc_df_fakedata(df_data,bkgBDT_run3)\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'fakedata_set3_run1'\n",
    "df_data = read_root('%s/fakedata/mcc9_v29e_dl_set3_fakedata_run1_numu_v1_1_3_fvv.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "# remember to turn off pmt precuts\n",
    "df_data_full = proc_df_fakedata(df_data,bkgBDT_run1)\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'fakedata_set3_run3b'\n",
    "df_data = read_root('%s/fakedata/mcc9_v29e_dl_set3_fakedata_run3b_numu_v1_1_3_fvv.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "# remember to turn off pmt precuts\n",
    "df_data_full = proc_df_fakedata(df_data,bkgBDT_run3)\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'fakedata_set2_run1'\n",
    "df_data = read_root('%s/fakedata/mcc9_v29e_dl_set2_fakedata_run1_numu_v1_1_3_fvv.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "# remember to turn off pmt precuts\n",
    "df_data_full = proc_df_fakedata(df_data,bkgBDT_run1)\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'fakedata_set2_run3b'\n",
    "df_data = read_root('%s/fakedata/mcc9_v29e_dl_set2_fakedata_run3b_numu_v1_1_3_fvv.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "# remember to turn off pmt precuts\n",
    "df_data_full = proc_df_fakedata(df_data,bkgBDT_run3)\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'fakedata_set4_run1'\n",
    "df_data = read_root('%s/fakedata/mcc9_v29e_dl_set4_fakedata_run1_numu_v1_1_3_fvv.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "# remember to turn off pmt precuts\n",
    "df_data_full = proc_df_fakedata(df_data,bkgBDT_run1)\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'fakedata_set4_run3b'\n",
    "df_data = read_root('%s/fakedata/mcc9_v29e_dl_set4_fakedata_run3b_numu_v1_1_3_fvv.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "# remember to turn off pmt precuts\n",
    "df_data_full = proc_df_fakedata(df_data,bkgBDT_run3)\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = 'fakedata_set5_run1'\n",
    "df_data = read_root('%s/fakedata/mcc9_v29e_dl_set5_fakedata_run1_numu_v1_1_3_fvv.root'%datafolder,'dlana/FinalVertexVariables')\n",
    "\n",
    "# remember to turn off pmt precuts\n",
    "df_data_full = proc_df_fakedata(df_data,bkgBDT_run1)\n",
    "\n",
    "df_data_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector Systematics (run3; not updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported format character 'm' (0x6d) at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4684ce0b3e64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms_mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'numu_run3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/bnb_overlay/mcc9_v29e_dl_run3b_bnb_nu_overlay_nocrtremerge_stripped.root'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdatafolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FinalVertexVariables'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_mc_cvweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%mc/bnb_overlay/weights_forCV_v40_bnb_nu_run3.root'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdatafolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_mc_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc_df_mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_mc_cvweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgood_run3_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported format character 'm' (0x6d) at index 1"
     ]
    }
   ],
   "source": [
    "s_mc = 'numu_run3'\n",
    "df_mc = read_root('%s/bnb_overlay/mcc9_v29e_dl_run3b_bnb_nu_overlay_nocrtremerge_stripped.root'%datafolder,'FinalVertexVariables')\n",
    "df_mc_cvweight = read_root('%mc/bnb_overlay/weights_forCV_v40_bnb_nu_run3.root'%datafolder)\n",
    "\n",
    "df_mc_full = proc_df_mc(df_mc,df_mc_cvweight,good_run3_df)  \n",
    "df_mc_full = df_bnb_full.query('not (nu_interaction_ccnc==0 and abs(nu_pdg)==12)') # cut out nue ccqes\n",
    "\n",
    "df_mc_full.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_mc,tag))\n",
    "\n",
    "del df_mc, df_mc_cvweight, df_mc_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_detvar_mc(df_dlana,df_cv,df_goodrun):\n",
    "    \n",
    "    df_cv['isCV'] = True\n",
    "    df_dlana['isCV'] = False\n",
    "    # Join cv and detsys together\n",
    "    # ugh. okay. this phase takes a million years so let's do it smarter\n",
    "    \n",
    "    df3_big = pd.concat((df_cv,df_dlana))\n",
    "    overlap = df_cv.merge(df_dlana[RSE],how='inner')[RSE].drop_duplicates()\n",
    "    df_full = df3_big.merge(overlap,how='inner')\n",
    "     \n",
    "    #df_full = pd.concat((df_dlana[df_dlana[RSE].isin(df_cv[RSE])],df_cv[df_cv[RSE].isin(df_dlana[RSE])])) \n",
    "    df_full_wGoodruns = df_full.join(df_goodrun.set_index('run'),on='run')\n",
    "    df_full_goodruns = df_full_wGoodruns.query('good == 1 and Enu_1m1p > 0')\n",
    "    df_full_goodruns.insert(0,'PassPrecuts1m1p',df_full_goodruns.apply(passPrecut,axis=1))     \n",
    "    return df_full_goodruns\n",
    "\n",
    "def passPrecut(row):\n",
    "    #orthogonalcut = 'MaxShrFrac < .2'\n",
    "    #precuts ='PassSimpleCuts == 1 and ChargeNearTrunk > 0 and FailedBoost != 1 and OpenAng > .5 and '\n",
    "    #s_precut = orthogonalcut + ' and ' + precuts\n",
    "    return (row['PassSimpleCuts'] == 1 and row['ChargeNearTrunk'] > 0 and row['FailedBoost'] != 1 and row['OpenAng'] > .5 and row['MaxShrFrac'] < .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_detvar_mc(df_dlana,df_cv,df_goodrun):\n",
    "    df_cv['isCV'] = True\n",
    "    df_dlana['isCV'] = False\n",
    "    \n",
    "    # Join cv and detsys together\n",
    "    df3_big = pd.concat((df_cv,df_dlana))\n",
    "    overlap = df_cv.merge(df_dlana[RSE],how='inner')[RSE].drop_duplicates()\n",
    "    df_full = df3_big.merge(overlap,how='inner')\n",
    "    \n",
    "    # add goodruns and 1m1p precut tag\n",
    "    df_full_wGoodruns = df_full.join(df_goodrun.set_index('run'),on='run')\n",
    "    df_full_goodruns = df_full_wGoodruns.query('good == 1 and Enu_1m1p > 0')\n",
    "    df_full_goodruns.insert(0,'PassPrecuts1m1p',df_full_goodruns.apply(passPrecut,axis=1))     \n",
    "    return df_full_goodruns#goodruns_precuts\n",
    "\n",
    "def passPrecut(row):\n",
    "    #orthogonalcut = 'MaxShrFrac < .2'\n",
    "    #precuts ='PassSimpleCuts == 1 and ChargeNearTrunk > 0 and FailedBoost != 1 and OpenAng > .5 and '\n",
    "    #s_precut = orthogonalcut + ' and ' + precuts\n",
    "    return (row['PassSimpleCuts'] == 1 and row['ChargeNearTrunk'] > 0 and row['FailedBoost'] != 1 and row['OpenAng'] > .5 and row['MaxShrFrac'] < .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done cv\n",
      "done wiremodThetaXZ\n",
      "done wiremodThetaYZ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcianci/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done LYdownRayleigh\n",
      "done SCE\n",
      "done LYdown\n",
      "done wiremodYZ\n",
      "done wiremodX\n",
      "done wiremoddEdx\n"
     ]
    }
   ],
   "source": [
    "df_cv = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_overlay_CV.root','FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/Pi0Sel/July27_CV_numu.txt',sep=',')\n",
    "df_passPi0['PassFinalSelectionPi0'] = 1\n",
    "df_cv_wPass = df_cv.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "print('done cv')\n",
    "\n",
    "s_data = 'wiremodThetaXZ'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodThetaXZ.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/Pi0Sel/July27_wiremodthetaXZ_numu.txt',sep=',')\n",
    "df_passPi0['PassFinalSelectionPi0'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'wiremodThetaYZ'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodThetaYZ.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/Pi0Sel/July27_wiremodthetaYZ_numu.txt',sep=',')\n",
    "df_passPi0['PassFinalSelectionPi0'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'LYdownRayleigh'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40_dl_run3b_bnb_nu_overlay_DetVar_LYRayleigh.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/Pi0Sel/July27_LYRayleigh_numu.txt',sep=',')\n",
    "df_passPi0['PassFinalSelectionPi0'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'SCE'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_SCE.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/Pi0Sel/July27_SCE_numu.txt',sep=',')\n",
    "df_passPi0['PassFinalSelectionPi0'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'LYdown'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_LYdown.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/Pi0Sel/July27_LYdown_numu.txt',sep=',')\n",
    "df_passPi0['PassFinalSelectionPi0'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'wiremodYZ'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_nu_overlay_DetVar_wiremodYZ.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/Pi0Sel/July27_wiremodYZ_numu.txt',sep=',')\n",
    "df_passPi0['PassFinalSelectionPi0'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'wiremodX'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_overlay_wiremodX.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/Pi0Sel/July27_wiremodX_numu.txt',sep=',')\n",
    "df_passPi0['PassFinalSelectionPi0'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'wiremoddEdx'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40_dl_run3b_bnb_nu_overlay_DetVar_wiremodscaleddedx.root','FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/Pi0Sel/July27_scaleddedx_numu.txt',sep=',')\n",
    "df_passPi0['PassFinalSelectionPi0'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donecv\n",
      "done wiremodX\n",
      "done LYdownRayleigh\n",
      "done LYdown\n",
      "done SCE\n",
      "done wiremoddEdx\n",
      "done wiremodThetaXZ\n",
      "done wiremodThetaYZ\n",
      "done wiremodYZ\n"
     ]
    }
   ],
   "source": [
    "#Detsys for nues now!\n",
    "df_cv = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_intrinsic_nue_overlay_CV.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/SystematicsForDavio/SystematicsForDavio_CV.txt',sep=',',names=['run','subrun','event','vtxid'])\n",
    "df_passPi0['PassFinalSelection1e1p'] = 1\n",
    "df_cv_wPass = df_cv.merge(df_passPi0,how='left')\n",
    "print('donecv')\n",
    "\n",
    "s_data = 'wiremodX'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_intrinsic_nue_overlay_wiremodX.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/SystematicsForDavio/SystematicsForDavio_WireModX.txt',sep=',',names=['run','subrun','event','vtxid'])\n",
    "df_passPi0['PassFinalSelection1e1p'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/nue_%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "\n",
    "s_data = 'LYdownRayleigh'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_intrinsic_nue_overlay_wiremodLYRayleigh.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/SystematicsForDavio/SystematicsForDavio_LYdownRayleigh.txt',sep=',',names=['run','subrun','event','vtxid'])\n",
    "df_passPi0['PassFinalSelection1e1p'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/nue_%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "\n",
    "s_data = 'LYdown'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_intrinsic_nue_overlay_wiremodLYdown.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/SystematicsForDavio/SystematicsForDavio_LYdown.txt',sep=',',names=['run','subrun','event','vtxid'])\n",
    "df_passPi0['PassFinalSelection1e1p'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/nue_%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'SCE'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v29e_dl_run3b_bnb_intrinsic_nue_wiremodSCE.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/SystematicsForDavio/SystematicsForDavio_SCE.txt',sep=',',names=['run','subrun','event','vtxid'])\n",
    "df_passPi0['PassFinalSelection1e1p'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/nue_%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'wiremoddEdx'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_intrinsic_nue_overlay_wiremodScaleddEdX.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/SystematicsForDavio/SystematicsForDavio_WireModdEdx.txt',sep=',',names=['run','subrun','event','vtxid'])\n",
    "df_passPi0['PassFinalSelection1e1p'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/nue_%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'wiremodThetaXZ'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_intrinsic_nue_overlay_wiremodThetaXZ.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/SystematicsForDavio/SystematicsForDavio_WireModThetaXZ.txt',sep=',',names=['run','subrun','event','vtxid'])\n",
    "df_passPi0['PassFinalSelection1e1p'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/nue_%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'wiremodThetaYZ'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_intrinsic_nue_overlay_wiremodThetaYZ.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/SystematicsForDavio/SystematicsForDavio_WireModThetaYZ.txt',sep=',',names=['run','subrun','event','vtxid'])\n",
    "df_passPi0['PassFinalSelection1e1p'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/nue_%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)\n",
    "\n",
    "s_data = 'wiremodYZ'\n",
    "df_bnb = read_root('../../data/detsys/mcc9_v40a_dl_run3b_bnb_intrinsic_nue_overlay_wiremodYZ.root','dlana/FinalVertexVariables')\n",
    "df_passPi0 = pd.read_table('../../data/detsys/SystematicsForDavio/SystematicsForDavio_WireModYZ.txt',sep=',',names=['run','subrun','event','vtxid'])\n",
    "df_passPi0['PassFinalSelection1e1p'] = 1\n",
    "df_bnb_wPass = df_bnb.join(df_passPi0.set_index(RSEV),on=RSEV)\n",
    "df_bnb_wCV_wPass_wProc = proc_detvar_mc(df_bnb_wPass,df_cv_wPass,good_run3_df)\n",
    "df_bnb_wCV_wPass_wProc.to_parquet('%s/pickles/nue_%s_%s.parquet'%(datafolder,s_data,tag))\n",
    "print('done %s'%s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POT Counting\n",
    "some old pot counting tools kept for posterity (and because I always forget how to use larlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dic_train_run3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5f2634b55152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpottree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotsummary_generator_branch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpottree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotsummary_generator_branch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpotsum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpottree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotsummary_generator_branch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotgoodpot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdic_train_run3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mpotsumtraining\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpottree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotsummary_generator_branch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotgoodpot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dic_train_run3' is not defined"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import ROOT as rt\n",
    "from array import array\n",
    "\n",
    "potsum = 0.0\n",
    "potsumtraining = 0.0\n",
    "sanitytest = 0.0\n",
    "\n",
    "rfile   = rt.TFile('../../data/potsummaries/potsum_mcc9_run3_bnb_overlay.root')\n",
    "pottree = rfile.Get(\"potsummary_generator_tree\")\n",
    "nentries = pottree.GetEntries() \n",
    "for ientry in range(nentries):\n",
    "    pottree.GetEntry(ientry)\n",
    "    idx = tuple((pottree.potsummary_generator_branch.run(),pottree.potsummary_generator_branch.subrun()))\n",
    "    potsum += pottree.potsummary_generator_branch.totgoodpot\n",
    "    if idx in dic_train_run3:\n",
    "        potsumtraining += pottree.potsummary_generator_branch.totgoodpot\n",
    "\n",
    "print(nentries)\n",
    "print(\"POT SUM: \",potsum)\n",
    "print(\"POT SUM IN TRAINING: \",potsumtraining)\n",
    "print(\"CORRECTEDPOTSUM:\",potsum-potsumtraining)\n",
    "print('TrainingFrac = ',(potsum-potsumtraining)/float(potsum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\u001b[95m    [NORMAL]  \u001b[0m\u001b[95m<open> \u001b[0mOpening a file in READ mode: ../../data/potsummaries/potsum_mcc9_run1_bnb_overlay.root\n",
      "\u001b[91m     [ERROR]  \u001b[0m\u001b[95m<prepare_tree> \u001b[0mDid not find any relevant data tree!\n",
      "\u001b[93m   [WARNING]  \u001b[0m\u001b[95m<close> \u001b[0mClosing a file without any I/O operation done!\n",
      "\u001b[91m     [ERROR]  \u001b[0m\u001b[95m<close> \u001b[0mAttempt to close file while not operating I/O!\n"
     ]
    }
   ],
   "source": [
    "import ROOT as rt\n",
    "from larlite import larlite\n",
    "io = larlite.storage_manager( larlite.storage_manager.kREAD )\n",
    "io.add_in_filename('../../data/potsummaries/potsum_mcc9_run1_bnb_overlay.root')\n",
    "io.open()\n",
    "ll_nentries  = io.get_entries()\n",
    "for ientry in range(ll_nentries):\n",
    "    io.go_to(ientry)\n",
    "    run = io.run_id()\n",
    "    subrun = io.subrun_id()\n",
    "    event = io.event_id()\n",
    "    print(run,subrun,event)\n",
    "io.close()\n",
    "print(ll_nentries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
